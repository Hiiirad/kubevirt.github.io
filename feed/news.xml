<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://kubevirt.io//feed/news.xml" rel="self" type="application/atom+xml" /><link href="https://kubevirt.io//" rel="alternate" type="text/html" /><updated>2021-01-18T20:49:56+00:00</updated><id>https://kubevirt.io//feed/news.xml</id><title type="html">KubeVirt.io | News</title><subtitle>Virtual Machine Management on Kubernetes</subtitle><entry><title type="html">KubeVirt Summit is coming!</title><link href="https://kubevirt.io//2021/KubeVirt-Summit-announce.html" rel="alternate" type="text/html" title="KubeVirt Summit is coming!" /><published>2021-01-12T00:00:00+00:00</published><updated>2021-01-12T00:00:00+00:00</updated><id>https://kubevirt.io//2021/KubeVirt-Summit-announce</id><content type="html" xml:base="https://kubevirt.io//2021/KubeVirt-Summit-announce.html">&lt;p&gt;Exciting news! The KubeVirt community are in the process of planning the first ever &lt;strong&gt;KubeVirt Summit&lt;/strong&gt;!&lt;/p&gt;

&lt;h2 id=&quot;save-the-dates&quot;&gt;Save the dates!&lt;/h2&gt;

&lt;p&gt;The event will take place online during two half-days:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Dates: February 9 and 10, 2021.&lt;/li&gt;
  &lt;li&gt;Time: 15:00 – 19:00 UTC (10:00–14:00 EST, 16:00–20:00 CET)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;proposing-topics&quot;&gt;Proposing topics&lt;/h2&gt;

&lt;p&gt;We want to encourage anyone who is interested in presenting to submit a topic to
our community repo
&lt;a href=&quot;https://github.com/kubevirt/community/tree/master/events/2021-kubevirt-summit/proposals&quot;&gt;here&lt;/a&gt;. Simply
copy the
&lt;a href=&quot;https://github.com/kubevirt/community/blob/master/events/2021-kubevirt-summit/proposals/proposal-template.md&quot;&gt;template&lt;/a&gt; in that repo directory as a new file, fill in the details pertaining to your
session, and submit your proposal as a Pull Request.&lt;/p&gt;

&lt;h2 id=&quot;keep-up-to-date&quot;&gt;Keep up to date&lt;/h2&gt;

&lt;p&gt;The event has a landing page &lt;a href=&quot;/summit/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;More details will be shared as they become available, here in the website and also on our &lt;a href=&quot;https://groups.google.com/forum/#!forum/kubevirt-dev&quot;&gt;mailing list&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/kubevirt&quot;&gt;twitter&lt;/a&gt; and our &lt;a href=&quot;https://calendar.google.com/calendar/embed?src=18pc0jur01k8f2cccvn5j04j1g%40group.calendar.google.com&amp;amp;ctz=Etc%2FGMT&quot;&gt;weekly community meetings&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Reach out through any of these channels to get involved.&lt;/p&gt;

&lt;p&gt;Looking forward to meeting you there!&lt;/p&gt;</content><author><name>Pep Turró Mauri</name></author><category term="news" /><category term="kubevirt" /><category term="event" /><category term="community" /><summary type="html">Exciting news! The KubeVirt community are in the process of planning the first ever KubeVirt Summit!</summary></entry><entry><title type="html">Customizing images for containerized VMs part I</title><link href="https://kubevirt.io//2020/Customizing-images-for-containerized-vms.html" rel="alternate" type="text/html" title="Customizing images for containerized VMs part I" /><published>2020-12-10T00:00:00+00:00</published><updated>2020-12-10T00:00:00+00:00</updated><id>https://kubevirt.io//2020/Customizing-images-for-containerized-vms</id><content type="html" xml:base="https://kubevirt.io//2020/Customizing-images-for-containerized-vms.html">&lt;p&gt;&lt;strong&gt;Table of contents&lt;/strong&gt;&lt;/p&gt;

&lt;!-- TOC depthFrom:2 insertAnchor:false orderedList:false updateOnSave:true withLinks:true --&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#the-vision&quot;&gt;The vision&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#preparation-of-the-environment&quot;&gt;Preparation of the environment&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#configuration-of-the-builder-image-server&quot;&gt;Configuration of the Builder image server&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#building-standard-centos-8-image&quot;&gt;Building standard CentOS 8 image&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#image-creation-with-builder-tool&quot;&gt;Image creation with Builder Tool&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#verify-the-custom-built-image&quot;&gt;Verify the custom-built image&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#image-tailoring-with-virt-customize&quot;&gt;Image tailoring with virt-customize&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#building-a-standard-centos-7-image-from-cloud-images&quot;&gt;Building a standard CentOS 7 image from cloud images&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#image-creation-with-virt-customize&quot;&gt;Image creation with virt-customize&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;!-- /TOC --&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Information&lt;/p&gt;&lt;p&gt;The content of this article has been divided into two: this one, which is the first part, explains how to create a golden image using different tools such as &lt;em&gt;Builder Tool&lt;/em&gt; and &lt;em&gt;virt-customize&lt;/em&gt;. Once the custom-built image is ready, it is containerized so that it can be uploaded and stored into a container registry. The second part deals with the different ways the developers can deploy, modify and connect to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VirtualMachineInstance&lt;/code&gt; running in the OKD Kubernetes cluster.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;the-vision&quot;&gt;The vision&lt;/h2&gt;

&lt;p&gt;If you work for a software factory, some kind of development environment standardization is probably in place. There are a lot of approaches which fit different use cases. In this blog post, our example company has allowed developers to choose their preferred editing tools and debugging environment locally to their workstations. However, before committing their changes to a Git repository, they need to validate them in a specifically tailored environment. This environment, due to legal restrictions, contains exact versions of the libraries, databases, web server or any other software previously agreed with customers.&lt;/p&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;Aside from the pre-commit environments, the company already has an automated continuous integration workflow composed by several shared environments: &lt;em&gt;development, integration and production&lt;/em&gt;.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This blog post focuses on showing a use case where containerized VMs running on top of Kubernetes ease the deployment and creation of standardized VMs to our developers. These VMs are meant to be ephemeral. However, if necessary, additional non-persistent disk or shared persistent storage can be attached so that important information can be kept safe.&lt;/p&gt;

&lt;p&gt;Along the process, different approaches and tools to create custom VM images that will be stored in a corporate registry are detailed. Containerizing VMs means adapting them so that they can be saved in a container registry. Being able to manage VMs as container images leverages the benefits of a container registry, such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The registry becomes a &lt;strong&gt;source of truth&lt;/strong&gt; for the VMs you want to run. Everybody can list all VMs available searching on a centralized point.&lt;/li&gt;
  &lt;li&gt;The container registry, depending on the storage size, contains historical information of all the VMs, which might have multiple different versions, identified by their tags. Any developer with the proper permissions is able to run any specific version of your standardized VM.&lt;/li&gt;
  &lt;li&gt;It is the unique point where all your VMs are stored avoiding having them spread all over your infrastructure.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Information&lt;/p&gt;&lt;p&gt;A container image registry is a service that stores container images, and is hosted either by a third-party or as a public/private registry such as Docker Hub, Quay, and so on.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The ambitious goal is allowing the developers to deploy standardized VMs on the current Kubernetes infrastructure. Then, execute the required tests and if they are good, push the code to the corporate Git repositories and delete the VM eventually.&lt;/p&gt;

&lt;p&gt;This goal is divided into three main procedures:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Create custom standardized VM images, also known as golden images.&lt;/li&gt;
  &lt;li&gt;Containerize the resulting golden VM images.&lt;/li&gt;
  &lt;li&gt;Deploy the proper VM images from the corporate registry into the OKD Kubernetes cluster.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;preparation-of-the-environment&quot;&gt;Preparation of the environment&lt;/h2&gt;

&lt;p&gt;Running containerized VMs in KubeVirt uses the &lt;a href=&quot;https://kubevirt.io/user-guide/#/creation/disks-and-volumes?id=containerdisk&quot;&gt;containerDisk&lt;/a&gt; feature which provides the ability to store and distributed VM disks in the container image registry. The disks are pulled from the container registry and reside on the local node hosting the VMs that consume the disks.&lt;/p&gt;

&lt;p&gt;The company already have an &lt;a href=&quot;https://www.okd.io/&quot;&gt;OKD 4 Kubernetes cluster&lt;/a&gt; installed which provides out of the box a container registry and some required security features such as &lt;em&gt;Role Based Access Controls (RBAC)&lt;/em&gt; and &lt;em&gt;Security Context Constraints (SCC)&lt;/em&gt;.&lt;/p&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Information&lt;/p&gt;&lt;p&gt;In the &lt;a href=&quot;https://blog.openshift.com/&quot;&gt;OpenShift blog&lt;/a&gt; there is a post called &lt;a href=&quot;https://blog.openshift.com/enterprise-kubernetes-with-openshift-part-one/&quot;&gt;Enterprise Kubernetes with OpenShift&lt;/a&gt; where you can find valuable information between the similarities and differences between OKD and Kubernetes.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;On top of the OKD cluster, KubeVirt is required so that we can run our virtual machines. The installation process is pretty well detailed in the &lt;a href=&quot;https://kubevirt.io/pages/cloud.html&quot;&gt;KubeVirt’s documentation&lt;/a&gt;. Below it is shown how KubeVirt components can be seen from the OKD web console.&lt;/p&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Information&lt;/p&gt;&lt;p&gt;KubeVirt version deployed is &lt;strong&gt;0.34.2&lt;/strong&gt; which is the latest at the moment of writing.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$KUBEVIRT_VERSION&lt;/span&gt;
0.34.2

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://github.com/kubevirt/kubevirt/releases/download/&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBEVIRT_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/kubevirt-operator.yaml
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://github.com/kubevirt/kubevirt/releases/download/&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBEVIRT_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/kubevirt-cr.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;my-gallery&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageGallery&quot;&gt;
  &lt;figure itemprop=&quot;associatedMedia&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageObject&quot;&gt;
    &lt;a href=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/kubevirt_okd.png&quot; itemprop=&quot;contentUrl&quot; data-size=&quot;1110x520&quot;&gt;
      &lt;img src=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/kubevirt_okd.png&quot; itemprop=&quot;thumbnail&quot; width=&quot;100%&quot; alt=&quot;VM to VM&quot; /&gt;
    &lt;/a&gt;
    &lt;figcaption itemprop=&quot;caption description&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;div class=&quot;premonition warning&quot;&gt;&lt;div class=&quot;fa fa-exclamation-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Warning&lt;/p&gt;&lt;p&gt;&lt;strong&gt;oc&lt;/strong&gt; is the specific command-line tool for OKD, however, it is based in &lt;em&gt;kubectl&lt;/em&gt; plus some additional features detailed here. It is probably that along the blog post, you can find executions with &lt;em&gt;oc&lt;/em&gt; or &lt;em&gt;kubectl&lt;/em&gt; interchangeably.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;containerDisks&lt;/code&gt; are created from RAW or &lt;a href=&quot;https://www.linux-kvm.org/page/Qcow2&quot;&gt;QCOW2&lt;/a&gt; virtual machine images. Nevertheless, virtual machine images with all the agreed software and proper configuration must be created previously. The company currently uses CentOS 7 as their approved base operating system to run their applications. However, during the last months, it has been encouraging to move to the recently released version 8 of CentOS.&lt;/p&gt;

&lt;p&gt;From a long time they had been using the prebuilt &lt;a href=&quot;https://cloud.centos.org/centos/&quot;&gt;CentOS cloud images&lt;/a&gt; with &lt;a href=&quot;http://libguestfs.org/virt-customize.1.html&quot;&gt;virt-customize&lt;/a&gt;, which allowed them to modify the prebuilt cloud images. As a trade-off, they had to trust on the cloud image provided by CentOS or verify if new packages were added on each release.&lt;/p&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Information&lt;/p&gt;&lt;p&gt;&lt;strong&gt;virt-customize&lt;/strong&gt; can customize a virtual machine (disk image) by installing packages, editing configuration files, and so on. Virt-customize modifies the guest or disk image in place.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now, they are starting to use a new tool called &lt;a href=&quot;https://docs.centos.org/en-US/centos/install-guide/Composer/&quot;&gt;Image Builder&lt;/a&gt; that creates deployment-ready customized system images from scratch. Furthermore, there is an integration with Cockpit where you can create custom CentOS images in various formats including QCOW2 for OpenStack, AMI (Amazon Machine Image), VHD (Azure Disk Image) etc. from a friendly user interface.&lt;/p&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;There are a lot of tools that can accomplish the objective of creating custom images. Here we are focusing on two: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;virt-customize&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Image Builder&lt;/code&gt;.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Along this blog post, both tools are used together in the image building process, leveraging their strengths. In the following diagram is depicted the different agents that take part in the process of running our standardized VMs in Kubernetes. This workflow includes the creation and customization of the images, their containerization, storing them into the OKD container registry and finally the creation of the VMs in Kubernetes by the employees.&lt;/p&gt;

&lt;div class=&quot;my-gallery&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageGallery&quot;&gt;
  &lt;figure itemprop=&quot;associatedMedia&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageObject&quot;&gt;
    &lt;a href=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/diagram-customizing-images.png&quot; itemprop=&quot;contentUrl&quot; data-size=&quot;1110x320&quot;&gt;
      &lt;img src=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/diagram-customizing-images.png&quot; itemprop=&quot;thumbnail&quot; width=&quot;100%&quot; alt=&quot;VM to VM&quot; /&gt;
    &lt;/a&gt;
    &lt;figcaption itemprop=&quot;caption description&quot;&gt;okd imageStream devstation&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;configuration-of-the-builder-image-server&quot;&gt;Configuration of the Builder image server&lt;/h3&gt;

&lt;p&gt;In order to prepare the building environment, it is recommended to install Image Builder in a dedicated server as it has specific security requirements. Actually, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lorax-composer&lt;/code&gt; which is one of its components doesn’t work properly with SELinux running, as it installs an entire OS image in an alternate directory.&lt;/p&gt;

&lt;div class=&quot;premonition warning&quot;&gt;&lt;div class=&quot;fa fa-exclamation-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Warning&lt;/p&gt;&lt;p&gt;As shown in the &lt;a href=&quot;https://weldr.io/Running-Composer-on-RHEL/&quot;&gt;lorax-composer documentation&lt;/a&gt; SELinux must be disabled. However, I have been able to create custom images successfully with SELinux enabled. In case you find any problems during your building, check the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lorax-composer&lt;/code&gt; logs in journal in order to get more detailed information.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here it is a table where the software required to run the builds along with the versions have been used.&lt;/p&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;Operating System is &lt;strong&gt;CentOS 8&lt;/strong&gt; since CentOS 7 Image Builder is still an &lt;a href=&quot;https://docs.centos.org/en-US/centos/install-guide/Composer/&quot;&gt;experimental feature&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Component&lt;/th&gt;
      &lt;th&gt;Version&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Operating System&lt;/td&gt;
      &lt;td&gt;CentOS Linux release 8.2.2004 (Core)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Libvirt&lt;/td&gt;
      &lt;td&gt;libvirtd (libvirt) 4.5.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;virt-customize&lt;/td&gt;
      &lt;td&gt;virt-customize 1.38.4rhel=8,release=14.module_el8.1.0+248+298dec18,libvirt&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Image Builder&lt;/td&gt;
      &lt;td&gt;lorax-composer (28.14.42-2), composer-cli (composer-cli-28.14.42-2), cockpit-composer (cockpit-composer-12.1-1.el8.noarch)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Once the builder image server is provisioned with latest CentOS 8, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Virtualization Host&lt;/code&gt; group package is installed. It will be required to test our customized images locally before containerizing and pushing them to the OKD registry.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;yum groupinstall &lt;span class=&quot;s2&quot;&gt;&quot;Virtualization Host&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;libvirtd &lt;span class=&quot;nt&quot;&gt;--now&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Next, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;virt-customize&lt;/code&gt; is installed from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;libguestfs-tools&lt;/code&gt; package along with the Image Builder. The latest is composed by lorax-composer, the Cockpit composer plugin and the composer-cli, which will be used to interact directly with Composer using command-line.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;dnf &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; libguestfs-tools lorax-composer composer-cli cockpit-composer
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;lorax-composer.socket
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;lorax-composer &lt;span class=&quot;nt&quot;&gt;--now&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;systemctl start cockpit
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Then, the local firewall is configured so that we can connect to the Cockpit web user interface from our workstation.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;firewall-cmd &lt;span class=&quot;nt&quot;&gt;--add-service&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;cockpit &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; firewall-cmd &lt;span class=&quot;nt&quot;&gt;--add-service&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;cockpit &lt;span class=&quot;nt&quot;&gt;--permanent&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Finally, connect to the Cockpit user interface by typing the IP or name of the Builder image server and port &lt;em&gt;TCP/9090&lt;/em&gt; (Cockpit’s default) in your favourite web browser. Then, log in with a local administrator account.&lt;/p&gt;

&lt;div class=&quot;my-gallery&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageGallery&quot;&gt;
  &lt;figure itemprop=&quot;associatedMedia&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageObject&quot;&gt;
    &lt;a href=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/cockpit-gui.png&quot; itemprop=&quot;contentUrl&quot; data-size=&quot;1110x484&quot;&gt;
      &lt;img src=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/cockpit-gui.png&quot; itemprop=&quot;thumbnail&quot; width=&quot;100%&quot; alt=&quot;VM to VM&quot; /&gt;
    &lt;/a&gt;
    &lt;figcaption itemprop=&quot;caption description&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The following image shows the Image Build plugin web page. Actually, what it is depicted are the different Image Build blueprints that are shipped by default. &lt;em&gt;The blueprint&lt;/em&gt; defines what should be included in your image. This includes packages, users, files, server settings …&lt;/p&gt;

&lt;div class=&quot;my-gallery&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageGallery&quot;&gt;
  &lt;figure itemprop=&quot;associatedMedia&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageObject&quot;&gt;
    &lt;a href=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/cockpit-first-page.png&quot; itemprop=&quot;contentUrl&quot; data-size=&quot;1110x333&quot;&gt;
      &lt;img src=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/cockpit-first-page.png&quot; itemprop=&quot;thumbnail&quot; width=&quot;100%&quot; alt=&quot;VM to VM&quot; /&gt;
    &lt;/a&gt;
    &lt;figcaption itemprop=&quot;caption description&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;div class=&quot;premonition error&quot;&gt;&lt;div class=&quot;fa fa-exclamation-triangle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Error&lt;/p&gt;&lt;p&gt;If Cockpit’s web UI is not working, take a look at the output of the lorax service with the command:&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;journalctl &lt;span class=&quot;nt&quot;&gt;-fu&lt;/span&gt; lorax-composer
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;


&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;building-standard-centos-8-image&quot;&gt;Building standard CentOS 8 image&lt;/h2&gt;

&lt;p&gt;It is time to create our standardized CentOS 8 image or also called golden CentOS 8 image. This image will be built from the ground up using the Image Builder tool.&lt;/p&gt;

&lt;h3 id=&quot;image-creation-with-builder-tool&quot;&gt;Image creation with Builder Tool&lt;/h3&gt;

&lt;p&gt;The easiest way to start is creating a new blueprint (devstation-centos8) from the Cockpit user interface. This will produce a scaffold file where all the required modifications can be made. Here it is shown the process of creation a new blueprint from Cockpit:&lt;/p&gt;

&lt;div class=&quot;my-gallery&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageGallery&quot;&gt;
  &lt;figure itemprop=&quot;associatedMedia&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageObject&quot;&gt;
    &lt;a href=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/create_blueprint.png&quot; itemprop=&quot;contentUrl&quot; data-size=&quot;1110x449&quot;&gt;
      &lt;img src=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/create_blueprint.png&quot; itemprop=&quot;thumbnail&quot; width=&quot;100%&quot; alt=&quot;VM to VM&quot; /&gt;
    &lt;/a&gt;
    &lt;figcaption itemprop=&quot;caption description&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;I would also suggest adding some users and all the packages you want to install from the user interface. In our case, we are going to create the following users by clicking on the details tab of the new blueprint. In both cases, the password is known by the respective group of users and also belongs to the wheel group.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Users&lt;/th&gt;
      &lt;th&gt;Note&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;sysadmin&lt;/td&gt;
      &lt;td&gt;Privileged user owned by the Systems Engineering team to troubleshoot and have access to the VM&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;developer&lt;/td&gt;
      &lt;td&gt;These are the credentials used by the developers to access the VM&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;my-gallery&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageGallery&quot;&gt;
  &lt;figure itemprop=&quot;associatedMedia&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageObject&quot;&gt;
    &lt;a href=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/users.png&quot; itemprop=&quot;contentUrl&quot; data-size=&quot;1110x380&quot;&gt;
      &lt;img src=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/users.png&quot; itemprop=&quot;thumbnail&quot; width=&quot;100%&quot; alt=&quot;VM to VM&quot; /&gt;
    &lt;/a&gt;
    &lt;figcaption itemprop=&quot;caption description&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Next, select the packages to include. Add the proper version of the package already agreed with the customer.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Package&lt;/th&gt;
      &lt;th&gt;Version&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;httpd&lt;/td&gt;
      &lt;td&gt;2.4.37&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mod_ssl&lt;/td&gt;
      &lt;td&gt;2.4.37&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;php&lt;/td&gt;
      &lt;td&gt;7.2.24&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mariadb-server&lt;/td&gt;
      &lt;td&gt;10.3.17&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;openssh-server&lt;/td&gt;
      &lt;td&gt;latest&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;At this point, you already have a blueprint template to start working. In addition to using the web console, you can also use the &lt;strong&gt;Image Builder CLI&lt;/strong&gt; to create images. When using the CLI, you have access to a few more customization options, such as managing firewall rules or download files from Git. Since we already have installed the composer-cli package in the &lt;a href=&quot;#configuration-of-the-builder-image-server&quot;&gt;Image Builder server&lt;/a&gt;, let’s use it to further customize our golden image.&lt;/p&gt;

&lt;p&gt;First, access to the Builder Image server and download the custom blueprint called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;devstation-centos8&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;composer-cli blueprints list
devstation-centos8
example-atlas
example-development
Example-http-server

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;composer-cli blueprints save devstation-centos8
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;ls
&lt;/span&gt;devstation-centos8.toml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Information&lt;/p&gt;&lt;p&gt;All composer-cli options are documented in the &lt;a href=&quot;https://weldr.io/lorax/composer-cli.html&quot;&gt;official webpage&lt;/a&gt;. Take a look if you need further detail.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now, let’s edit the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;devstation-centos8.toml&lt;/code&gt; file which is in charge of building our custom image.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The time zone has been added to match Europe/Madrid with proper NTP servers.&lt;/li&gt;
  &lt;li&gt;The kernel has been modified to allow connection via console.&lt;/li&gt;
  &lt;li&gt;Several firewall rules have been added to allow our services being accessed from outside.&lt;/li&gt;
  &lt;li&gt;Some services have been configured so that they are enabled and started at boot.&lt;/li&gt;
  &lt;li&gt;A Git repository has been configured to be cloned. Actually, it is a Git repository that contains a manual detailing how the custom image is configured and how it must be used.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;premonition warning&quot;&gt;&lt;div class=&quot;fa fa-exclamation-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Warning&lt;/p&gt;&lt;p&gt;It is important to add console as a kernel option since the Builder Image tool disables access to serial console by default. It will allow the &lt;em&gt;virtctl&lt;/em&gt; command to connect to the VM while it is booting in our OKD Kubernetes cluster.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is the final building configuration file, it can be downloaded from &lt;a href=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/devstation-centos8.toml&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-toml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;py&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;devstation-centos8&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;description&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;A developer station&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;0.0.1&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;modules&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;groups&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[[packages]]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;httpd&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;2.4.37&quot;&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[[packages]]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;mod_ssl&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;2.4.37&quot;&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[[packages]]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;php&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;7.2.24&quot;&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[[packages]]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;mariadb-server&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;10.3.17&quot;&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[[packages]]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;openssh-server&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;*&quot;&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[customizations]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;hostname&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;devstation&quot;&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[customizations.kernel]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;append&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;console=tty0 console=ttyS0,19200n81&quot;&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[customizations.timezone]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;timezone&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Europe/Madrid&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;ntpservers&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.europe.pool.ntp.org&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1.europe.pool.ntp.org&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[[customizations.user]]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;sysadmin&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;description&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Company Systems Admin&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;password&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;$6$ZGmDxvGu3Q0M4RO/$KkfU0bD32FrLNpUCWEL8sy3dknJVyqExoy.NJMOcSCRjpt1H6sFKFjx8mFWn8H5CWTP7.bibPLBrRSRq3MrDb.&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;home&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/home/sysadmin/&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;shell&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/usr/bin/bash&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;groups&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;users&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;wheel&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[[customizations.user]]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;developer&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;description&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;developer&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;groups&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;[&quot;wheel&quot;]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;password&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;$6$wlIgNacMnqCcXn3o$mPpw0apT4iZ3jDq0q6epXN3xCmNN.oVGFW.Gvu9r0nDVX.FXY3iCwfFkfPEcmhj7Kxw4Ppoes2LsUzPtNRjez0&quot;&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[customizations.services]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;enabled&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;[&quot;httpd&quot;,&quot;mariadb&quot;,&quot;sshd&quot;]&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[customizations.firewall.services]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;enabled&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;[&quot;http&quot;,&quot;https&quot;,&quot;mysql&quot;,&quot;ssh&quot;]&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[[repos.git]]&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;rpmname&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;manual&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;rpmversion&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1.0&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;rpmrelease&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;summary&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Manual how to work with devstation&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;repo&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;https://github.com/alosadagrande/lorax&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;ref&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;master&quot;&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;destination&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/var/www/html/manual&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;In this case, we are using a Git repository to download useful information on how to deal with the customized image. However, it is possible to download for instance code or other information that can be stored in Git. And what is most important, it is versioned.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Once edited, push the configuration to Image Builder and start the building process by selecting the blueprint and the output format. Builder Image tool can export the same blueprint into multiple output formats. Thus, one blueprint might create the same custom image running on multiple providers (qcow2 in our case).&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;composer-cli blueprints push devstation-centos8.toml

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;composer-cli compose start devstation-centos8 qcow2
Compose 248161f5-0870-41e8-b871-001348395ca7 added to the queue
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;It is possible to verify that the modified blueprint has been pushed successfully by executing the show command.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;composer-cli blueprints show devstation-centos8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The building process can take tens of minutes. It is possible to see the process by checking the lorax-composer logs in the journal or request the status of the blueprint built from the composer-cli:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;composer-cli compose status
248161f5-0870-41e8-b871-001348395ca7 RUNNING  Fri Nov 27 15:12:09 2020 devstation-centos8 0.0.2 qcow2

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;journalctl &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt; lorax-composer &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt;
Nov 27 15:13:31 eko3.cloud.lab.eng.bos.redhat.com lorax-composer[38218]: 2020-11-27 15:13:31,715: Installing.
Nov 27 15:13:31 eko3.cloud.lab.eng.bos.redhat.com lorax-composer[38218]: 2020-11-27 15:13:31,716: Starting package installation process
Nov 27 15:13:31 eko3.cloud.lab.eng.bos.redhat.com lorax-composer[38218]: 2020-11-27 15:13:31,716: Downloading packages
Nov 27 15:13:31 eko3.cloud.lab.eng.bos.redhat.com lorax-composer[38218]: 2020-11-27 15:13:31,716: Downloading 474 RPMs, 3.75 MiB / 396.83 MiB &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0%&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
Nov 27 15:13:31 eko3.cloud.lab.eng.bos.redhat.com lorax-composer[38218]: 2020-11-27 15:13:31,716: Downloading 474 RPMs, 15.58 MiB / 396.83 MiB &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;3%&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once the building process is finished, it is time to download the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QCOW2&lt;/code&gt; file. It can be downloaded from Cockpit UI or from the composer-cli:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;composer-cli compose image 248161f5-0870-41e8-b871-001348395ca7
248161f5-0870-41e8-b871-001348395ca7-disk.qcow2: 1854.31 MB

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-lhrt&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-rw-r--r--&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;  1 root root 1.5K Nov 27 15:11 devstation-centos8.toml
&lt;span class=&quot;nt&quot;&gt;-rw-r--r--&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;  1 root root 1.9G Nov 27 15:26 248161f5-0870-41e8-b871-001348395ca7-disk.qcow2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Afterwards, the image is suggested to be renamed to something more meaningful. Below the information given by qemu is exhibited:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;mv &lt;/span&gt;248161f5-0870-41e8-b871-001348395ca7-disk.qcow2  golden-devstation-centos8-disk.qcow2

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;qemu-img info golden-devstation-centos8-disk.qcow2
image: golden-devstation-centos8-disk.qcow2
file format: qcow2
virtual size: 4.3G &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;4566548480 bytes&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
disk size: 1.8G
cluster_size: 65536
Format specific information:
    compat: 1.1
    lazy refcounts: &lt;span class=&quot;nb&quot;&gt;false
    &lt;/span&gt;refcount bits: 16
    corrupt: &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;premonition warning&quot;&gt;&lt;div class=&quot;fa fa-exclamation-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Warning&lt;/p&gt;&lt;p&gt;Virtual size of the image is 4.3G, since we agreed 10G the disk must be resized and root filesystem expanded before being containerized. Currently, there is no way to specify disk capacity in containerDisk as it can be done with &lt;a href=&quot;https://github.com/kubevirt/kubevirt/blob/master/docs/container-empty-disks.md#implementation&quot;&gt;emptyDisks&lt;/a&gt;. The size of the root filesystem and disk when running in KubeVirt is driven by the image.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;premonition warning&quot;&gt;&lt;div class=&quot;fa fa-exclamation-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Warning&lt;/p&gt;&lt;p&gt;It is recommended to save the QCOW2 images under /var/lib/libvirt/images/ so that qemu user have permissions to expand or resize them.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;qemu-img resize golden-devstation-centos8-disk.qcow2 10G
Image resized.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The expansion is executed on the root partition, which in case of our golden image is &lt;strong&gt;/dev/sda2&lt;/strong&gt; partition. It must be checked previously, for instance using the &lt;em&gt;virt-filesystems&lt;/em&gt; utility:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;virt-filesystems &lt;span class=&quot;nt&quot;&gt;--partitions&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--long&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; golden-devstation-centos8-disk.qcow2
Name       Type       MBR  Size        Parent
/dev/sda1  partition  83   1073741824  /dev/sda
/dev/sda2  partition  83   2966421504  /dev/sda
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Note that a &lt;strong&gt;copy of the golden image&lt;/strong&gt; is created and that’s the one expanded.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cp &lt;/span&gt;golden-devstation-centos8-disk.qcow2 golden-devstation-centos8-disk-10G.qcow2
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;virt-resize &lt;span class=&quot;nt&quot;&gt;--expand&lt;/span&gt; /dev/sda2  golden-devstation-centos8-disk.qcow2 golden-devstation-centos8-disk-10G.qcow2
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;   0.0] Examining golden-devstation-centos8-disk-10G.qcow2
&lt;span class=&quot;k&quot;&gt;**********&lt;/span&gt;

Summary of changes:

/dev/sda1: This partition will be left alone.

/dev/sda2: This partition will be resized from 2.7G to 9.0G.  The
filesystem xfs on /dev/sda2 will be expanded using the ‘xfs_growfs’
method.

&lt;span class=&quot;k&quot;&gt;**********&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;   2.2] Setting up initial partition table on golden-devstation-centos8-disk-10G.qcow2
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;   3.1] Copying /dev/sda1
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;   4.0] Copying /dev/sda2
 100%
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;   8.5] Expanding /dev/sda2 using the ‘xfs_growfs’ method

Resize operation completed with no errors.  Before deleting the old disk,
carefully check that the resized disk boots and works correctly.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, it is verified that the image meets the expected size (see virtual size):&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;qemu-img info golden-devstation-centos8-disk-10G.qcow2
image: golden-devstation-centos8-disk-10G.qcow2
file format: qcow2
virtual size: 10G &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;10737418240 bytes&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
disk size: 1.8G
cluster_size: 65536
Format specific information:
    compat: 1.1
    lazy refcounts: &lt;span class=&quot;nb&quot;&gt;false
    &lt;/span&gt;refcount bits: 16
    corrupt: &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;In case the developers are allowed to select between multiple flavours, e.g. different root filesystem sizes, you will end up with multiple containerized VM images. In the event that an additional block device is needed, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;emptyDisk&lt;/code&gt; is the proper way to go.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;verify-the-custom-built-image&quot;&gt;Verify the custom-built image&lt;/h3&gt;

&lt;p&gt;Before continuing, it is suggested to verify the golden expanded image. Since the qcow2 image is not yet containerized, it can easily run on KVM/libvirt. In our case, the builder server has already in place the &lt;em&gt;Virtualization Host&lt;/em&gt; group packages.&lt;/p&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Information&lt;/p&gt;&lt;p&gt;There are a lot of tools that allow us to run a qcow2 image in libvirt. In this example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;virt-install&lt;/code&gt; is used, however, other tool that makes easy to deploy VM images and worth exploring is &lt;a href=&quot;https://github.com/karmab/kcli&quot;&gt;kcli&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;First, install &lt;a href=&quot;https://linux.die.net/man/1/virt-install&quot;&gt;virt-install&lt;/a&gt;, which is a command-line tool for creating new KVM, Xen, or Linux container guests using the “libvirt” hypervisor management library, and run a new VM from the golden image:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;yum &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;virt-install &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;virt-install &lt;span class=&quot;nt&quot;&gt;--version&lt;/span&gt;
2.2.1

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;virt-install &lt;span class=&quot;nt&quot;&gt;--memory&lt;/span&gt; 2048 &lt;span class=&quot;nt&quot;&gt;--vcpus&lt;/span&gt; 2 &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; devstation-centos8 &lt;span class=&quot;nt&quot;&gt;--disk&lt;/span&gt; /var/lib/libvirt/images/golden-devstation-centos8-disk-10G.qcow2,device&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;disk &lt;span class=&quot;nt&quot;&gt;--os-type&lt;/span&gt; Linux &lt;span class=&quot;nt&quot;&gt;--os-variant&lt;/span&gt; rhel8.1 &lt;span class=&quot;nt&quot;&gt;--virt-type&lt;/span&gt; kvm &lt;span class=&quot;nt&quot;&gt;--graphics&lt;/span&gt; none &lt;span class=&quot;nt&quot;&gt;--network&lt;/span&gt; default &lt;span class=&quot;nt&quot;&gt;--import&lt;/span&gt;

Starting install...
Connected to domain devstation-centos8
Escape character is ^]

CentOS Linux 8 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Core&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Kernel 4.18.0-147.5.1.el8_1.x86_64 on an x86_64
devstation login:
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Login as &lt;a href=&quot;#image-creation-with-builder-tool&quot;&gt;developer or sysadmin user&lt;/a&gt;, scale privileges and check that the VM is configured as expected.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;firewall-cmd &lt;span class=&quot;nt&quot;&gt;--list-all&lt;/span&gt;
public &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;active&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  target: default
  icmp-block-inversion: no
  interfaces: ens3
  sources:
  services: cockpit dhcpv6-client http https mysql ssh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;systemctl is-active httpd
active
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;systemctl is-active mariadb
active
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;systemctl is-active sshd
active
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Verify the disk and partition sizes are correctly configured:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;lsblk
NAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
vda    252:0    0  10G  0 disk
├─vda1 252:1    0   1G  0 part /boot
└─vda2 252:2    0   9G  0 part /

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-h&lt;/span&gt;
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        962M     0  962M   0% /dev
tmpfs           995M     0  995M   0% /dev/shm
tmpfs           995M   17M  979M   2% /run
tmpfs           995M     0  995M   0% /sys/fs/cgroup
/dev/vda2       9.0G  1.9G  7.2G  21% /
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;In case you are unsure on which partition you need to expand or contains the root filesystem, just run a VM from the golden qcow2 image and execute the previous commands. Then delete the VM and expand the image accordingly.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Finally, notice how the cloned repository has been copied successfully during the built process. Users can check the custom image information connecting to the local Apache server:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@devstation ~]# curl localhost/manual/
Dear developer,
&amp;lt;br&amp;gt;
&amp;lt;br&amp;gt;
Welcome to the devstation server.

&amp;lt;h2&amp;gt; How to use the devstation server &amp;lt;/h2&amp;gt;

Remember that before committing your changes to the corporate &lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;management control server, you need to validate your code here.

&amp;lt;h2&amp;gt; Need &lt;span class=&quot;nb&quot;&gt;help&lt;/span&gt;? &amp;lt;/h2&amp;gt;

Please contact us at sysadmin@corporate.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;image-tailoring-with-virt-customize&quot;&gt;Image tailoring with virt-customize&lt;/h3&gt;

&lt;p&gt;In the previous section, we verified that the golden image was successfully built. However, there are still a few things that need to be added so that the golden image can be successfully containerized and run on top of our OKD Kubernetes cluster.&lt;/p&gt;

&lt;p&gt;First, a worthy package that is suggested to be included in the golden image is &lt;a href=&quot;https://cloud-init.io/&quot;&gt;cloud-init&lt;/a&gt;. KubeVirt allows you to create VM objects along with &lt;a href=&quot;https://kubevirt.io/user-guide/#/creation/cloud-init?id=startup-scripts&quot;&gt;cloud-init&lt;/a&gt; configurations. Cloud-init will let our developers further adapt the custom image to their application needs. On the other hand, it has been agreed with the Software Engineering team to add a graphical interface to the custom image since there are developers that are not familiar with the terminal.&lt;/p&gt;

&lt;p&gt;The result will be &lt;strong&gt;two golden images CentOS 8&lt;/strong&gt;, both with cloud-init, but one will include a GUI and the other is terminal-based and therefore much lighter.&lt;/p&gt;

&lt;div class=&quot;premonition warning&quot;&gt;&lt;div class=&quot;fa fa-exclamation-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Warning&lt;/p&gt;&lt;p&gt;It is important to set the memsize of the building process to 4096m and have expanded the root filesystem otherwise you will face an out of space or/and out of memory error while installing the GNOME GUI.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cp &lt;/span&gt;golden-devstation-centos8-disk-10G.qcow2 golden-devstation-centos8-disk-10G-gui.qcow2
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;virt-customize &lt;span class=&quot;nt&quot;&gt;--format&lt;/span&gt; qcow2 &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; /var/lib/libvirt/images/golden-devstation-centos8-disk-10G.qcow2 &lt;span class=&quot;nt&quot;&gt;--install&lt;/span&gt; cloud-init &lt;span class=&quot;nt&quot;&gt;--memsize&lt;/span&gt; 4096 &lt;span class=&quot;nt&quot;&gt;--selinux-relabel&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;virt-customize &lt;span class=&quot;nt&quot;&gt;--format&lt;/span&gt; qcow2 &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; /var/lib/libvirt/images/golden-devstation-centos8-disk-10G-gui.qcow2 &lt;span class=&quot;nt&quot;&gt;--install&lt;/span&gt; @graphical-server-environment,cloud-init &lt;span class=&quot;nt&quot;&gt;--memsize&lt;/span&gt; 4096 &lt;span class=&quot;nt&quot;&gt;--run-command&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;systemctl set-default graphical.target&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--selinux-relabel&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;At this point we built:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A golden CentOS 8 image which can run on libvirt/KVM virtualization servers (golden-devstation-centos8-disk.qcow2)&lt;/li&gt;
  &lt;li&gt;A 10G CentOS 8 image prepared to be executed by KubeVirt including cloud-init. (golden-devstation-centos8-disk-10G.qcow2)&lt;/li&gt;
  &lt;li&gt;A 10G CentOS 8 image prepared to be executed by KubeVirt including both cloud-init and GNOME GUI (golden-devstation-centos8-disk-10G-gui.qcow2)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;building-a-standard-centos-7-image-from-cloud-images&quot;&gt;Building a standard CentOS 7 image from cloud images&lt;/h2&gt;

&lt;p&gt;In the previous section, it was shown how we can build and customize images from scratch using the Builder Image tool. However, there are settings that could not be configured even with the composer-cli. Thus, &lt;em&gt;virt-customize&lt;/em&gt; is used to fine-tune the custom image, i.e, add cloud-init and a graphical user interface.&lt;/p&gt;

&lt;p&gt;Since the Builder Tool is an &lt;a href=&quot;https://docs.centos.org/en-US/centos/install-guide/Composer/&quot;&gt;experimental tool in CentOS 7&lt;/a&gt;, the company continues creating their golden CentOS 7 images based on CentOS cloud images. Comparing with the CentOS 8 workflow, the cloud image corresponds to the golden image even it is not built by the Systems Engineering department.&lt;/p&gt;

&lt;div class=&quot;premonition warning&quot;&gt;&lt;div class=&quot;fa fa-exclamation-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Warning&lt;/p&gt;&lt;p&gt;Note that with CentOS 7 images, the company is trusting a cloud image provided by a third party instead of creating one from scratch.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;image-creation-with-virt-customize&quot;&gt;Image creation with virt-customize&lt;/h3&gt;

&lt;p&gt;The process to create the golden CentOS 7 image is quite similar to the CentOS 8 one. However, in this case, the customize procedure is entirely done with &lt;em&gt;virt-customize&lt;/em&gt;. The first step is to download the cloud image.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; /var/lib/libvirt/images/golden-devstation-centos7-disk.qcow2 https://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud.qcow2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Then, it is required to resize and expand the image to meet the agreed size of 10GB. The details are the same explained in the &lt;a href=&quot;#image-creation-with-builder-tool&quot;&gt;previous section&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;qemu-img info golden-devstation-centos7-disk.qcow2
image: golden-devstation-centos7-disk.qcow2
file format: qcow2
virtual size: 8.0G &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;8589934592 bytes&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
disk size: 819M
cluster_size: 65536
Format specific information:
    compat: 1.1
    lazy refcounts: &lt;span class=&quot;nb&quot;&gt;false
    &lt;/span&gt;refcount bits: 16
    corrupt: &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;qemu-img resize golden-devstation-centos7-disk.qcow2 10G
Image resized.

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cp &lt;/span&gt;golden-devstation-centos7-disk.qcow2 golden-devstation-centos7-disk-10G.qcow2
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;virt-resize &lt;span class=&quot;nt&quot;&gt;--expand&lt;/span&gt; /dev/sda1  golden-devstation-centos7-disk.qcow2 golden-devstation-centos7-disk-10G.qcow2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;premonition warning&quot;&gt;&lt;div class=&quot;fa fa-exclamation-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Warning&lt;/p&gt;&lt;p&gt;In this case, unlike CentOS 8 image, the partition where the root filesystem resides is &lt;strong&gt;/dev/sda1&lt;/strong&gt;. That’s the partition that needs to be expanded.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Below it is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;virt-customize&lt;/code&gt; command that modifies the CentOS 7 &lt;em&gt;expanded&lt;/em&gt; cloud image by:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Installing the required packages (however, not the exact versions)&lt;/li&gt;
  &lt;li&gt;Changing the root password&lt;/li&gt;
  &lt;li&gt;Setting devstation as hostname to the customized image&lt;/li&gt;
  &lt;li&gt;Configuring the time zone&lt;/li&gt;
  &lt;li&gt;Enabling the installed services&lt;/li&gt;
  &lt;li&gt;Including files from the manual.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;Manual files must be pulled first from &lt;a href=&quot;https://github.com/alosadagrande/lorax&quot;&gt;alosadagrande/lorax&lt;/a&gt; GitHub repository.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;virt-customize &lt;span class=&quot;nt&quot;&gt;--format&lt;/span&gt; qcow2 &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; /var/lib/libvirt/images/golden-devstation-centos7-disk-10G.qcow2 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                                &lt;span class=&quot;nt&quot;&gt;--install&lt;/span&gt; cloud-init,mod_ssl,httpd,mariadb-server,php,openssh-server &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                                &lt;span class=&quot;nt&quot;&gt;--memsize&lt;/span&gt; 4096  &lt;span class=&quot;nt&quot;&gt;--hostname&lt;/span&gt; devstation  &lt;span class=&quot;nt&quot;&gt;--selinux-relabel&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--timezone&lt;/span&gt; Europe/Madrid &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                                &lt;span class=&quot;nt&quot;&gt;--root-password&lt;/span&gt; password:toor &lt;span class=&quot;nt&quot;&gt;--password&lt;/span&gt; centos:password:developer123 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                                &lt;span class=&quot;nt&quot;&gt;--run-command&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'systemctl enable httpd'&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--run-command&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'systemctl enable mariadb'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                                &lt;span class=&quot;nt&quot;&gt;--mkdir&lt;/span&gt; /var/www/html/manual &lt;span class=&quot;nt&quot;&gt;--upload&lt;/span&gt; ~/lorax/index.html:/var/www/html/manual/index.html
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Information&lt;/p&gt;&lt;p&gt;Instead of executing all parameters in the command-line it is possible to create a file that is used as an input file for &lt;em&gt;virt-customize&lt;/em&gt;. See option &lt;a href=&quot;http://libguestfs.org/virt-customize.1.html&quot;&gt;commands-from-file&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Next, we need to create the graphical user interface image in a similar way as we did previously with CentOS 8 image.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cp &lt;/span&gt;golden-devstation-centos7-disk-10G.qcow2 golden-devstation-centos7-disk-10G-gui.qcow2

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;virt-customize &lt;span class=&quot;nt&quot;&gt;--format&lt;/span&gt; qcow2 &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; /var/lib/libvirt/images/golden-devstation-centos7-disk-10G-gui.qcow2 &lt;span class=&quot;nt&quot;&gt;--install&lt;/span&gt; cloud-init &lt;span class=&quot;nt&quot;&gt;--memsize&lt;/span&gt; 4096 &lt;span class=&quot;nt&quot;&gt;--run-command&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;yum groupinstall 'GNOME Desktop' -y&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--run-command&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;systemctl set-default graphical.target&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--selinux-relabel&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At this point we built:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A golden CentOS 7 image which can run on libvirt/KVM virtualization servers (golden-devstation-centos7-disk.qcow2).&lt;/li&gt;
  &lt;li&gt;A 10G CentOS 7 image prepared to be executed by KubeVirt which includes cloud-init (golden-devstation-centos7-disk-10G.qcow2).&lt;/li&gt;
  &lt;li&gt;A 10G CentOS 7 image prepared to be executed by KubeVirt which includes cloud-init and GNOME GUI (golden-devstation-centos7-disk-10G-gui.qcow2).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;image-containerization-procedure&quot;&gt;Image containerization procedure&lt;/h2&gt;

&lt;p&gt;The procedure to inject a &lt;em&gt;VirtualMachineInstance&lt;/em&gt; disk into a container images is pretty well explained in &lt;a href=&quot;https://kubevirt.io/user-guide/#/creation/disks-and-volumes?&quot;&gt;containerDisk Workflow example&lt;/a&gt; from the official documentation. Only RAW and QCOW2 formats are supported and the disk it is recommended to be placed into the /disk directory inside the container. Actually, it can be placed in other directories, but then, it must be explicitly configured when creating the &lt;em&gt;VirtualMachine&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Currently, there are 4 standardized images ready to be containerized. The process is the same for all of them, so in order to keep it short, we are just going to show the process of creating a container image from the CentOS 8 QCOW2 images.&lt;/p&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Information&lt;/p&gt;&lt;p&gt;These are the four available images: CentOS 8 with GNOME, CentOS 8 terminal only, CentOS 7 with GNOME and CentOS 7 terminal only.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;EOF&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt; &amp;gt; Containerfile
FROM scratch
ADD golden-devstation-centos8-disk-10G.qcow2 /disk/
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;Containerfile
FROM scratch
ADD golden-devstation-centos8-disk-10G-gui.qcow2 /disk/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, it is time to build the image. In our case, &lt;a href=&quot;https://podman.io/&quot;&gt;podman&lt;/a&gt; has chosen to execute the task, however, we could have used &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;buildah&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;podman build &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; openshift/devstation-centos8:terminal
STEP 1: FROM scratch
STEP 2: ADD golden-devstation-centos8-disk-10G.qcow2 /disk/
STEP 3: COMMIT openshift/devstation-centos8:terminal
8a9e83db71f08995fa73699c4e5a2d331c61b393daa18aa0b63269dc10078467

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;podman build &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; openshift/devstation-centos8:gui
STEP 1: FROM scratch
STEP 2: ADD golden-devstation-centos8-disk-10G-gui.qcow2 /disk/
STEP 3: COMMIT openshift/devstation-centos8:gui
2a4ecc7bf9da91bcb5847fd1cf46f4cd10726a4ceae88815eb2a9ab38b316be4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After the successful build, the images are stored locally to the local server, in our case the Builder Server. Remember that they must be uploaded to the OKD container registry.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;podman images
REPOSITORY                               TAG        IMAGE ID       CREATED          SIZE
localhost/openshift/devstation-centos8   gui        2a4ecc7bf9da   3 minutes ago    5.72 GB
localhost/openshift/devstation-centos8   terminal   8a9e83db71f0   13 minutes ago   1.94 GB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;store-the-image-in-the-container-registry&quot;&gt;Store the image in the container registry&lt;/h3&gt;

&lt;p&gt;Before pushing the images to the corporate container registry, it must be verified that the OKD registry is available outside the Kubernetes cluster. This allows any authenticated user to gain external access to push images into the OKD Kubernetes cluster. &lt;a href=&quot;https://docs.openshift.com/container-platform/4.3/registry/securing-exposing-registry.html&quot;&gt;Exposing the secure registry&lt;/a&gt; consists basically on configuring a route and expose that route in the OKD routers. Once done, external &lt;strong&gt;authenticated&lt;/strong&gt; access is allowed.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;oc get route &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; openshift-image-registry
NAME            HOST/PORT                                                     PATH   SERVICES         PORT    TERMINATION   WILDCARD
default-route   default-route-openshift-image-registry.apps.okd.okdlabs.com          image-registry   &amp;lt;all&amp;gt;   reencrypt     None
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;In order to upload your containerized images to the OKD registry, the user must be authenticated and &lt;a href=&quot;https://docs.openshift.com/container-platform/4.3/registry/accessing-the-registry.html&quot;&gt;authorized to execute the push action&lt;/a&gt;. The role that must be added to the OKD user is the &lt;em&gt;registry-editor&lt;/em&gt;&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In order to authenticate with the OKD container registry, podman is employed as explained in the &lt;a href=&quot;https://docs.openshift.com/container-platform/4.3/registry/securing-exposing-registry.html&quot;&gt;official documentation&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;oc login https://api.okd.okdlabs.com:6443 &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt; alosadag
The server uses a certificate signed by an unknown authority.
You can bypass the certificate check, but any data you send to the server could be intercepted by others.
Use insecure connections? &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;y/n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: y

Authentication required &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;https://api.okd.okdlabs.com:6443 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;openshift&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Username: alosadag
Password:
Login successful.

&lt;span class=&quot;nv&quot;&gt;$ HOST&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;oc get route default-route &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; openshift-image-registry &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;jsonpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'{.spec.host }'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOST&lt;/span&gt;
default-route-openshift-image-registry.apps.okd.okdlabs.com

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt; podman login &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;oc &lt;span class=&quot;nb&quot;&gt;whoami&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;oc &lt;span class=&quot;nb&quot;&gt;whoami&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--tls-verify&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOST&lt;/span&gt;
Login Succeeded!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Before pushing the images, adapt container images to the proper name so they can be uploaded to private registries. Since it is agreed that all developers must be able to pull the images into their namespaces, the images need to be pushed to the openshift project.&lt;/p&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Information&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://docs.openshift.com/container-platform/4.6/openshift_images/images-understand.html&quot;&gt;Understanding containers, images and imageStreams&lt;/a&gt; from OpenShift documentation deeply explains container image naming.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;podman tag localhost/openshift/devstation-centos8:gui default-route-openshift-image-registry.apps.okd.okdlabs.com/openshift/devstation:v8-terminal
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;podman push default-route-openshift-image-registry.apps.okd.okdlabs.com/openshift/devstation:v8-terminal &lt;span class=&quot;nt&quot;&gt;--tls-verify&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;podman tag localhost/openshift/devstation-centos:gui default-route-openshift-image-registry.apps.okd.okdlabs.com/openshift/devstation:v8-gui
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;podman push default-route-openshift-image-registry.apps.okd.okdlabs.com/openshift/devstation:v8-gui &lt;span class=&quot;nt&quot;&gt;--tls-verify&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Verify that the images are stored correctly in the OKD container registry by checking the &lt;a href=&quot;https://docs.openshift.com/container-platform/4.6/openshift_images/image-streams-manage.html#working-with-imagestreams&quot;&gt;imageStream&lt;/a&gt;. As shown below, both images were uploaded successfully since the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;devstation&lt;/code&gt; imageStream contains two images with v8-gui and v8-terminal tags respectively.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;oc describe imageStream devstation &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; openshift
Name:			devstation
Namespace:		openshift
Created:		23 hours ago
Labels:			&amp;lt;none&amp;gt;
Annotations:		&amp;lt;none&amp;gt;
Image Repository:	default-route-openshift-image-registry.apps.okd.okdlabs.com/openshift/devstation
Image Lookup:		&lt;span class=&quot;nb&quot;&gt;local&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false
&lt;/span&gt;Unique Images:		2
Tags:			2

v8-gui
  no spec tag

  &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; image-registry.openshift-image-registry.svc:5000/openshift/devstation@sha256:e301d935c1cb5a64d41df340d78e6162ddb0ede9b9b5df9c20df10d78f8fde0f
      2 hours ago

v8-terminal
  no spec tag

  &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; image-registry.openshift-image-registry.svc:5000/openshift/devstation@sha256:47c2ba0c463da84fa1569b7fb8552c07167f3464a9ce3b6e3f607207ba4cee65
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At this point, the images are stored in a private registry and ready to be consumed by the developers.&lt;/p&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Information&lt;/p&gt;&lt;p&gt;In case you do not have a corporate private registry available, you can upload images to any free public container registry. Then, consume the container images from the public container registry. Just in case you want to use them or take a look, it has been uploaded to my &lt;a href=&quot;https://quay.io/repository/alosadag/devstation?tab=tags&quot;&gt;public container image repository at quay.io&lt;/a&gt;&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;my-gallery&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageGallery&quot;&gt;
  &lt;figure itemprop=&quot;associatedMedia&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageObject&quot;&gt;
    &lt;a href=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/okd_is_devstation.png&quot; itemprop=&quot;contentUrl&quot; data-size=&quot;1110x467&quot;&gt;
      &lt;img src=&quot;/assets/2020-12-01-Customizing-images-for-containerized-vms/okd_is_devstation.png&quot; itemprop=&quot;thumbnail&quot; width=&quot;100%&quot; alt=&quot;VM to VM&quot; /&gt;
    &lt;/a&gt;
    &lt;figcaption itemprop=&quot;caption description&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In the next article, we will show how our developers can consume the custom-built images to run into the OKD Kubernetes cluster.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In this blog post, it was detailed a real use of a company that uses KubeVirt to run standardized environments to run and test the code of their applications. In their use case, VMs are spinned up on-demand in the OKD Kubernetes cluster by the developers. This makes them completely autonomous creating and deleting their environments once the tasks are accomplished.&lt;/p&gt;

&lt;p&gt;The article explained how to create a golden image using different tools such as Builder Tool and virt-customize. Once the custom-built image was ready, then it is transformed into a container image so that it can be uploaded and stored into a container registry.&lt;/p&gt;

&lt;div class=&quot;premonition info&quot;&gt;&lt;div class=&quot;fa fa-info-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Information&lt;/p&gt;&lt;p&gt;In the next blog post, the custom-built containerized VM will be deployed from our corporate registry into our Kubernetes cluster. We will show how the developers can fine-tune even more the image deployment, how extra storage can be requested and how to connect to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VirtualMachineInstance&lt;/code&gt;. Stay tuned!&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://kubevirt.io/pages/cloud.html&quot;&gt;KubeVirt installation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://developers.redhat.com/blog/2019/05/08/red-hat-enterprise-linux-8-image-builder-building-custom-system-images/&quot;&gt;Image Builder: Building custom system images&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://weldr.io/lorax/composer-cli.html&quot;&gt;Composer-cli information&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://quay.io/repository/alosadag/devstation?tab=tags&quot;&gt;Custom-built images available at quay.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Alberto Losada Grande</name></author><category term="news" /><category term="kubevirt" /><category term="kubernetes" /><category term="virtual machine" /><category term="okd" /><category term="containerDisk" /><category term="registry" /><category term="composer-cli" /><category term="virt-customize" /><category term="builder tool" /><summary type="html">Table of contents</summary></entry><entry><title type="html">High Availability – RunStrategies for Virtual Machines</title><link href="https://kubevirt.io//2020/run_strategies.html" rel="alternate" type="text/html" title="High Availability – RunStrategies for Virtual Machines" /><published>2020-12-04T00:00:00+00:00</published><updated>2020-12-04T00:00:00+00:00</updated><id>https://kubevirt.io//2020/run_strategies</id><content type="html" xml:base="https://kubevirt.io//2020/run_strategies.html">&lt;h1 id=&quot;why-isnt-my-vm-running&quot;&gt;Why Isn’t My VM Running?&lt;/h1&gt;

&lt;p&gt;There’s been a longstanding point of confusion in KubeVirt’s API. One that was raised yet again a few times recently. The confusion stems from the “Running” field of the VM spec. Language has meaning. It’s natural to take it at face value that “Running” means “Running”, right? Well, not so fast.&lt;/p&gt;

&lt;h1 id=&quot;spec-vs-status&quot;&gt;Spec vs Status&lt;/h1&gt;

&lt;p&gt;KubeVirt objects follow Kubernetes convention in that they generally have Spec and Status stanzas. The Spec is user configurable and allows the user to indicate the desired state of the cluster in a declarative manner. Meanwhile status sections are not user configurable and reflect the actual state of things in the cluster. In short, users edit the Spec and controllers edit the Status.&lt;/p&gt;

&lt;p&gt;So back to the Running field. In this case the Running field is in the VM’s Spec. In other words it’s the user’s intent that the VM is running. It doesn’t reflect the actual running state of the VM.&lt;/p&gt;

&lt;h1 id=&quot;runstrategy&quot;&gt;RunStrategy&lt;/h1&gt;

&lt;p&gt;There’s a flip side to the above, equally as confusing: “Running” isn’t always what the user wants. If a user logs into a VM and shuts it down from inside the guest, KubeVirt will dutifully re-spawn it! There certainly exist high availability use cases where that’s exactly the correct reaction, but in most cases that’s just plain confusing. Shutdown is not restart!&lt;/p&gt;

&lt;p&gt;We decided to tackle both issues at the same time–by deprecating the “Running” field. As already noted, we could have picked a better name to begin with. By using the name “RunStrategy”, it should hopefully be more clear to the end user that they’re asking for a state, which is of course completely separate from what the system can actually provide. While RunStrategy helps address the nomenclature confusion, it also happens to be an enumerated value. Since Running is a boolean, it can only be true or false. We’re now able to create more meaningful states to accommodate different use cases.&lt;/p&gt;

&lt;h2 id=&quot;four-runstrategies-currently-exist&quot;&gt;Four RunStrategies currently exist:&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Always: If a VM is stopped for any reason, a new instance will be spawned.&lt;/li&gt;
  &lt;li&gt;RerunOnFailure: If a VM ends execution in an error state, a new instance will be spawned. This addressed the second concern listed above. If a user halts a VM manually a new instance will not be spawned.&lt;/li&gt;
  &lt;li&gt;Manual: This is exactly what it means. KubeVirt will neither attempt to start or stop a VM. In order to change state, the user must invoke start/stop/restart from the API. There exist convenience functions in the virtctl command line client as well.&lt;/li&gt;
  &lt;li&gt;Halted: The VM will be stopped if it’s running, and will remain off.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An example using the RerunOnFailure RunStrategy was presented in &lt;a href=&quot;/2020/KubeVirt-VM-Image-Usage-Patterns.html&quot;&gt;KubeVirt VM Image Usage Patterns&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;high-availability&quot;&gt;High Availability&lt;/h1&gt;

&lt;p&gt;No discussion of RunStrategies is complete without mentioning High Availability. After all, the implication behind the RerunOnFailure and Always RunStrategies is that your VM should always be available. For the most part this is completely true, but there’s one important scenario where there’s a gap to be aware of: if a node fails completely, e.g. loss of networking or power. Without some means of automatic detection that the node is no longer active, KubeVirt won’t know that the VM has failed. On OpenShift clusters installed using Installer Provisioned Infrastructure (IPI) with MachineHealthCheck enabled can detect failed nodes and reschedule workloads running there.&lt;/p&gt;

&lt;p&gt;Mode information on IPI and MHC can be found here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.openshift.com/container-platform/4.6/installing/installing_bare_metal_ipi/ipi-install-overview.html#ipi-install-overview&quot;&gt;Installer Provisioned Infrastructure&lt;/a&gt;
&lt;a href=&quot;https://docs.openshift.com/container-platform/4.6/machine_management/deploying-machine-health-checks.html&quot;&gt;Machine Health Check&lt;/a&gt;&lt;/p&gt;</content><author><name>Stu Gott</name></author><category term="news" /><category term="kubevirt" /><category term="Kubernetes" /><category term="virtual machine" /><category term="VM" /><summary type="html">Why Isn’t My VM Running?</summary></entry><entry><title type="html">Multiple Network Attachments with bridge CNI</title><link href="https://kubevirt.io//2020/Multiple-Network-Attachments-with-bridge-CNI.html" rel="alternate" type="text/html" title="Multiple Network Attachments with bridge CNI" /><published>2020-10-21T00:00:00+00:00</published><updated>2020-10-21T00:00:00+00:00</updated><id>https://kubevirt.io//2020/Multiple-Network-Attachments-with-bridge-CNI</id><content type="html" xml:base="https://kubevirt.io//2020/Multiple-Network-Attachments-with-bridge-CNI.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Over the last years the KubeVirt project has improved a lot regarding secondary interfaces networking configuration. Now it’s possible to do an end to end configuration from host networking to a VM using just the Kubernetes API with
special Custom Resource Definitions. Moreover, the deployment of all the projects has been simplified by introducing &lt;a href=&quot;https://github.com/kubevirt/hyperconverged-cluster-operator&quot;&gt;KubeVirt hyperconverged cluster operator (HCO)&lt;/a&gt; and &lt;a href=&quot;https://github.com/kubevirt/cluster-network-addons-operator&quot;&gt;cluster network addons operator (CNAO)&lt;/a&gt; to install the networking components.&lt;/p&gt;

&lt;p&gt;The following is the operator hierarchy list presenting the deployment responsibilities of the HCO and CNAO operators used in this blog post:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;kubevirt-hyperconverged-cluster-operator (HCO)
    &lt;ul&gt;
      &lt;li&gt;cluster-network-addons-operator (CNAO)
        &lt;ul&gt;
          &lt;li&gt;multus&lt;/li&gt;
          &lt;li&gt;bridge-cni&lt;/li&gt;
          &lt;li&gt;kubemacpool&lt;/li&gt;
          &lt;li&gt;kubernetes-nmstate&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;KubeVirt&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introducing-cluster-network-addons-operator&quot;&gt;Introducing cluster-network-addons-operator&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/kubevirt/cluster-network-addons-operator&quot;&gt;cluster network addons operator&lt;/a&gt; manages the lifecycle (deploy/update/delete) of different Kubernetes network components needed to
configure secondary interfaces, manage MAC addresses and defines networking on hosts for pods and VMs.&lt;/p&gt;

&lt;p&gt;A Good thing about having an operator is that everything is done through the API and you don’t have to go over all nodes to install these components yourself and assures smooth updates.&lt;/p&gt;

&lt;p&gt;In this blog post we are going to use the following components, explained in a greater detail later on:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;multus: to start a secondary interface on containers in pods&lt;/li&gt;
  &lt;li&gt;linux bridge CNI: to use bridge CNI and connect the secondary interfaces from pods to a linux bridge at nodes&lt;/li&gt;
  &lt;li&gt;kubemacpool: to manage mac addresses&lt;/li&gt;
  &lt;li&gt;kubernetes-nmstate: to configure the linux bridge on the nodes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The list of components we want CNAO to deploy is specified by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NetworkAddonsConfig&lt;/code&gt; Custom Resource (CR) and the progress of the installation appears in the CR status field, split per component. To inspect
this progress we can query the CR status with the following command:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get NetworkAddonsConfig cluster &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To simplify this blog post we are going to use directly the NetworkAddonsConfig from HCO, which by default installs all the network components, but just to illustrate CNAO configuration, the following is a NetworkAddonsConfig CR instructing to deploy multus, linuxBridge, nmstate and kubemacpool components:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;networkaddonsoperator.network.kubevirt.io/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;NetworkAddonsConfig&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cluster&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;multus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;linuxBridge&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;nmstate&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Always&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;connecting-pods-vms-and-nodes-over-a-single-secondary-network-with-bridge-cni&quot;&gt;Connecting Pods, VMs and Nodes over a single secondary network with bridge CNI&lt;/h2&gt;

&lt;p&gt;Although Kubernetes provides a default interface that gives connectivity to pods and VMs, it’s not easy to configure which NIC should be used for specific pods or VMs in a multi NIC node cluster. A Typical use case is to split control/traffic planes isolated by different NICs on nodes.&lt;/p&gt;

&lt;p&gt;With linux bridge CNI + multus it’s possible to create a secondary NIC in pod containers and attach it to a L2 linux bridge on nodes. This will add container’s connectivity to a specific NIC on nodes if that NIC is part of the L2 linux bridge.&lt;/p&gt;

&lt;p&gt;To ensure the configuration is applied only in pods on nodes that have the bridge, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k8s.v1.cni.cncf.io/resourceName&lt;/code&gt; label is added. This goes hand in hand with another component, &lt;a href=&quot;https://github.com/kubevirt/bridge-marker&quot;&gt;bridge-marker&lt;/a&gt; which inspects nodes networking and if a new bridge pops up it will mark the node status with it.&lt;/p&gt;

&lt;p&gt;This is an example of the results from bridge-marker on nodes where bridge br0 is already configured:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;allocatable&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;bridge.network.kubevirt.io/br0&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1k&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;capacity&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;bridge.network.kubevirt.io/br0&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1k&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is an example of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NetworkAttachmentDefinition&lt;/code&gt; to expose the bridge available on the host to users:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;k8s.cni.cncf.io/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;NetworkAttachmentDefinition&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bridge-network&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;annotations&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;k8s.v1.cni.cncf.io/resourceName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bridge.network.kubevirt.io/br0&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;cniVersion&quot;: &quot;0.3.1&quot;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;name&quot;: &quot;br0-l2&quot;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;plugins&quot;: [{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;type&quot;: &quot;bridge&quot;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;bridge&quot;: &quot;br0&quot;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;ipam&quot;: {}&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;}]&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then adding the bridge secondary network to a pod is a matter of adding the following annotation to
it:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;annotations&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;k8s.v1.cni.cncf.io/networks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bridge-network&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;setting-up-node-networking-with-nodenetworkconfigurationpolicy-aka-nncp&quot;&gt;Setting up node networking with NodeNetworkConfigurationPolicy (aka nncp)&lt;/h2&gt;

&lt;p&gt;Changing Kubernetes cluster node networking can be done manually iterating over all the cluster nodes and making changes or using different automatization tools like ansible. However, using just another Kubernetes resource is more convenient.
For this purpose the kubernetes-nmstate project was born as a cluster wide node network administrator based on Kubernetes CRs on top of &lt;a href=&quot;https://github.com/nmstate/nmstate&quot;&gt;nmstate&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It works as a Kubernetes &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DaemonSet&lt;/code&gt; running pods on all the cluster nodes and reconciling three different CRs:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/nmstate/kubernetes-nmstate/master/deploy/crds/nmstate.io_v1beta1_nodenetworkconfigurationpolicy_cr.yaml&quot;&gt;NodeNetworkConfigurationPolicy&lt;/a&gt; to specify cluster node network desired configuration&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/nmstate/kubernetes-nmstate/master/deploy/crds/nmstate.io_v1beta1_nodenetworkconfigurationenactment_cr.yaml&quot;&gt;NodeNetworkConfigurationEnactment&lt;/a&gt; (nnce) to troubleshoot issues with nncp&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/nmstate/kubernetes-nmstate/master/deploy/crds/nmstate.io_v1beta1_nodenetworkstate_cr.yaml&quot;&gt;NodeNetworkState&lt;/a&gt; (nns) to view the node’s networking configuration&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;Project kubernetes-nmstate has a distributed architecture to reduce kube-apiserver connectivity dependency, this means that every pod will configure the networking on the node that it’s running without much interaction with kube-apiserver.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In case something goes wrong and the pod changing the node network cannot ping the default gateway, resolve DNS root servers or has lost the kube-apiserver connectivity it will rollback to the previous configuration to go back to a working state. Those errors can be checked by running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubectl get nnce&lt;/code&gt;. The command displays potential issues per node and nncp.&lt;/p&gt;

&lt;p&gt;The desired state fields follow the nmstate API described at their &lt;a href=&quot;https://www.nmstate.io/&quot;&gt;awesome doc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Also for more details on kubernetes-nmstate there are guides covering &lt;a href=&quot;https://github.com/nmstate/kubernetes-nmstate/blob/master/docs/user-guide/101-reporting.md&quot;&gt;reporting&lt;/a&gt;, &lt;a href=&quot;https://github.com/nmstate/kubernetes-nmstate/blob/master/docs/user-guide/102-configuration.md&quot;&gt;configuration&lt;/a&gt; and &lt;a href=&quot;https://github.com/nmstate/kubernetes-nmstate/blob/master/docs/user-guide/103-troubleshooting.md&quot;&gt;troubleshooting&lt;/a&gt;. There are also &lt;a href=&quot;https://github.com/nmstate/kubernetes-nmstate/tree/master/docs/examples&quot;&gt;nncp examples&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;demo-mixing-it-all-together-vm-to-vm-communication-between-nodes&quot;&gt;Demo: mixing it all together, VM to VM communication between nodes&lt;/h2&gt;

&lt;p&gt;With the following recipe we will end up with a pair of virtual machines pair on two different nodes with one secondary NICs, eth1 at vlan 100. They will be connected to each other using
the same bridge on nodes that also have the external secondary NIC eth1 connected.&lt;/p&gt;

&lt;h3 id=&quot;demo-environment-setup&quot;&gt;Demo environment setup&lt;/h3&gt;

&lt;p&gt;We are going to use a &lt;a href=&quot;https://github.com/kubevirt/kubevirtci&quot;&gt;kubevirtci&lt;/a&gt; as Kubernetes ephemeral cluster provider.&lt;/p&gt;

&lt;p&gt;To start it up with two nodes and one secondary NIC and install NetworkManager &amp;gt;= 1.22 (needed for kubernetes-nmstate) and dnsmasq follow these steps:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/kubevirt/kubevirtci
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;kubevirtci
&lt;span class=&quot;c&quot;&gt;# Pin to version working with blog post steps in case&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# k8s-1.19 provider disappear in the future&lt;/span&gt;
git reset d5d8e3e376b4c3b45824fbfe320b4c5175b37171 &lt;span class=&quot;nt&quot;&gt;--hard&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBEVIRT_PROVIDER&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;k8s-1.19
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBEVIRT_NUM_NODES&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBEVIRT_NUM_SECONDARY_NICS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1
make cluster-up
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBECONFIG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;./cluster-up/kubeconfig.sh&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;installing-components&quot;&gt;Installing components&lt;/h3&gt;

&lt;p&gt;To install KubeVirt we are going to use the operator &lt;a href=&quot;https://github.com/kubevirt/hyperconverged-cluster-operator&quot;&gt;kubevirt-hyper-converged-operator&lt;/a&gt;, this will install all the components
needed to have a functional KubeVirt with all the features including the ones we are going to use: multus, linux-bridge, kubemacpool and kubernetes-nmstate.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl https://raw.githubusercontent.com/kubevirt/hyperconverged-cluster-operator/master/deploy/deploy.sh | bash
kubectl &lt;span class=&quot;nb&quot;&gt;wait &lt;/span&gt;hco &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; kubevirt-hyperconverged kubevirt-hyperconverged &lt;span class=&quot;nt&quot;&gt;--for&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Available &lt;span class=&quot;nt&quot;&gt;--timeout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;500s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we have a Kubernetes cluster with all the pieces to startup a VM with bridge attached to a secondary NIC.&lt;/p&gt;

&lt;h3 id=&quot;creating-the-br0-on-nodes-with-a-port-attached-to-secondary-nic-eth1&quot;&gt;Creating the br0 on nodes with a port attached to secondary NIC eth1&lt;/h3&gt;

&lt;p&gt;First step is to create a L2 linux-bridge at nodes with one port on the secondary NIC eth1, this will be
used later on by the bridge CNI.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;cat &amp;lt;&amp;lt;EOF | kubectl apply -f -&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nmstate.io/v1alpha1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;NodeNetworkConfigurationPolicy&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;br0-eth1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;desiredState&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;interfaces&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;br0&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Linux bridge with eth1 as a port&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;linux-bridge&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;up&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;bridge&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;stp&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;enabled&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;eth1&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we wait for the bridge to be created checking nncp conditions:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl &lt;span class=&quot;nb&quot;&gt;wait &lt;/span&gt;nncp br0-eth1 &lt;span class=&quot;nt&quot;&gt;--for&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Available &lt;span class=&quot;nt&quot;&gt;--timeout&lt;/span&gt; 2m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After the nncp becomes available, we can query the nncp resources in the cluster
and see it listed with successful status.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get nncp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;NAME       STATUS
br0-eth1   SuccessfullyConfigured
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can inspect the status of applying the policy to each node.
For that there is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NodeNetworkConfigurationEnactment&lt;/code&gt; CR (nnce):&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get nnce
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;NAME              STATUS
node01.br0-eth1   SuccessfullyConfigured
node02.br0-eth1   SuccessfullyConfigured
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;In case of errors it is possible to retrieve the error dumped by nmstate running
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubectl get nnce -o yaml&lt;/code&gt; the status will contain the error.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We can also inspect the network state on the nodes by retrieving the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NodeNetworkState&lt;/code&gt; and
checking if the bridge &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;br0&lt;/code&gt; is up using jsonpath&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get nns node01 &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;jsonpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'{.status.currentState.interfaces[?(@.name==&quot;br0&quot;)].state}'&lt;/span&gt;
kubectl get nns node02 &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;jsonpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'{.status.currentState.interfaces[?(@.name==&quot;br0&quot;)].state}'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When inspecting the full currentState yaml we get the following
interface configuration:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get nns node01 &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;currentState&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;interfaces&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;bridge&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;group-forward-mask&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;mac-ageing-time&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;300&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;multicast-snooping&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;stp&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;enabled&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;forward-delay&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;hello-time&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;max-age&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;priority&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;32768&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;eth1&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;stp-hairpin-mode&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;stp-path-cost&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;stp-priority&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;32&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Linux bridge with eth1 as a port&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;ipv4&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;dhcp&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;enabled&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;ipv6&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;autoconf&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;dhcp&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;enabled&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;mac-address&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;52:55:00:D1:56:00&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;mtu&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1500&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;br0&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;up&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;linux-bridge&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can also check that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bridge-marker&lt;/code&gt; is working and check verify on nodes:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get node node01 &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following should appear stating that br0
can be consumed on the node:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;allocatable&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;bridge.network.kubevirt.io/br0&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1k&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;capacity&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;bridge.network.kubevirt.io/br0&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1k&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At this point we have an L2 linux bridge ready and connected to NIC eth1.&lt;/p&gt;

&lt;h3 id=&quot;configure-network-attachment-with-a-l2-bridge-and-a-vlan&quot;&gt;Configure network attachment with a L2 bridge and a vlan&lt;/h3&gt;

&lt;p&gt;In order to make the bridge a L2 bridge, we specify no IPAM (IP Address Management) since we are
not going to configure any ip address for the bridge. To configure
bridge vlan-filtering we add the vlan we want to use to isolate our VMs:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;cat &amp;lt;&amp;lt;EOF | kubectl apply -f -&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;k8s.cni.cncf.io/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;NetworkAttachmentDefinition&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;br0-100-l2&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;annotations&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;k8s.v1.cni.cncf.io/resourceName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bridge.network.kubevirt.io/br0&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;cniVersion&quot;: &quot;0.3.1&quot;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;name&quot;: &quot;br0-100-l2-config&quot;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;plugins&quot;: [&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;type&quot;: &quot;bridge&quot;,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;bridge&quot;: &quot;br0&quot;,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;vlan&quot;: 100,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;ipam&quot;: {}&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;},&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;type&quot;: &quot;tuning&quot;&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;start-a-pair-of-vms-on-different-nodes-using-the-multus-configuration-to-connect-a-secondary-interfaces-to-br0&quot;&gt;Start a pair of VMs on different nodes using the multus configuration to connect a secondary interfaces to br0&lt;/h3&gt;

&lt;p&gt;Now it’s time to startup the VMs running on different nodes so we can check external connectivity of
br0. They will also have a secondary NIC eth1 to connect to the other VM running at different node, so they go
over the br0 at nodes.&lt;/p&gt;

&lt;p&gt;The following picture illustrates the cluster:&lt;/p&gt;

&lt;!-- yaspeller ignore:start --&gt;

&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot; width=&quot;292pt&quot; height=&quot;287pt&quot; viewBox=&quot;0.00 0.00 292.00 286.51&quot;&gt;
&lt;g id=&quot;graph0&quot; class=&quot;graph&quot; transform=&quot;scale(1 1) rotate(0) translate(4 282.5052)&quot;&gt;
&lt;title&gt;bridge&lt;/title&gt;
&lt;polygon fill=&quot;#ffffff&quot; stroke=&quot;transparent&quot; points=&quot;-4,4 -4,-282.5052 288,-282.5052 288,4 -4,4&quot; /&gt;
&lt;g id=&quot;clust1&quot; class=&quot;cluster&quot;&gt;
&lt;title&gt;cluster_kubevirtci&lt;/title&gt;
&lt;polygon fill=&quot;#3cb371&quot; stroke=&quot;#3cb371&quot; points=&quot;8,-8 8,-270.5052 276,-270.5052 276,-8 8,-8&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;142&quot; y=&quot;-253.9052&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot; fill=&quot;#000000&quot;&gt;kubevirtci cluster&lt;/text&gt;
&lt;/g&gt;
&lt;g id=&quot;clust2&quot; class=&quot;cluster&quot;&gt;
&lt;title&gt;cluster_node01&lt;/title&gt;
&lt;polygon fill=&quot;#8b864e&quot; stroke=&quot;#8b864e&quot; points=&quot;146,-72 146,-237.7052 268,-237.7052 268,-72 146,-72&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;207&quot; y=&quot;-221.1052&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot; fill=&quot;#000000&quot;&gt;node01&lt;/text&gt;
&lt;/g&gt;
&lt;g id=&quot;clust3&quot; class=&quot;cluster&quot;&gt;
&lt;title&gt;cluster_vma&lt;/title&gt;
&lt;polygon fill=&quot;#b4cdcd&quot; stroke=&quot;#b4cdcd&quot; points=&quot;204,-80 204,-160.9052 260,-160.9052 260,-80 204,-80&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;232&quot; y=&quot;-144.3052&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot; fill=&quot;#000000&quot;&gt;vma&lt;/text&gt;
&lt;/g&gt;
&lt;g id=&quot;clust4&quot; class=&quot;cluster&quot;&gt;
&lt;title&gt;cluster_node02&lt;/title&gt;
&lt;polygon fill=&quot;#8b864e&quot; stroke=&quot;#8b864e&quot; points=&quot;16,-72 16,-237.7052 138,-237.7052 138,-72 16,-72&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;77&quot; y=&quot;-221.1052&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot; fill=&quot;#000000&quot;&gt;node02&lt;/text&gt;
&lt;/g&gt;
&lt;g id=&quot;clust5&quot; class=&quot;cluster&quot;&gt;
&lt;title&gt;cluster_vmb&lt;/title&gt;
&lt;polygon fill=&quot;#b4cdcd&quot; stroke=&quot;#b4cdcd&quot; points=&quot;74,-80 74,-160.9052 130,-160.9052 130,-80 74,-80&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;102&quot; y=&quot;-144.3052&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot; fill=&quot;#000000&quot;&gt;vmb&lt;/text&gt;
&lt;/g&gt;
&lt;!-- nd_br1_kubevirtci --&gt;
&lt;g id=&quot;node1&quot; class=&quot;node&quot;&gt;
&lt;title&gt;nd_br1_kubevirtci&lt;/title&gt;
&lt;polygon fill=&quot;#ffd700&quot; stroke=&quot;#ffd700&quot; points=&quot;127,-52 91,-52 91,-16 127,-16 127,-52&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;109&quot; y=&quot;-29.8&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot; fill=&quot;#000000&quot;&gt;br1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- nd_br0_node01 --&gt;
&lt;g id=&quot;node2&quot; class=&quot;node&quot;&gt;
&lt;title&gt;nd_br0_node01&lt;/title&gt;
&lt;polygon fill=&quot;#ffd700&quot; stroke=&quot;#ffd700&quot; points=&quot;221,-204.9052 185,-204.9052 185,-168.9052 221,-168.9052 221,-204.9052&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;203&quot; y=&quot;-182.7052&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot; fill=&quot;#000000&quot;&gt;br0&lt;/text&gt;
&lt;/g&gt;
&lt;!-- nd_eth1_node01 --&gt;
&lt;g id=&quot;node3&quot; class=&quot;node&quot;&gt;
&lt;title&gt;nd_eth1_node01&lt;/title&gt;
&lt;polygon fill=&quot;#ffd700&quot; stroke=&quot;#ffd700&quot; points=&quot;194.1053,-128.1579 153.8947,-128.1579 153.8947,-87.9473 194.1053,-87.9473 194.1053,-128.1579&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;174&quot; y=&quot;-103.8526&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot; fill=&quot;#000000&quot;&gt;eth1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- nd_br0_node01&amp;#45;&amp;#45;nd_eth1_node01 --&gt;
&lt;g id=&quot;edge3&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;nd_br0_node01--nd_eth1_node01&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;#000000&quot; d=&quot;M196.2739,-168.6166C191.8232,-156.5147 185.985,-140.6405 181.4024,-128.18&quot; /&gt;
&lt;/g&gt;
&lt;!-- nd_eth1_vma --&gt;
&lt;g id=&quot;node4&quot; class=&quot;node&quot;&gt;
&lt;title&gt;nd_eth1_vma&lt;/title&gt;
&lt;polygon fill=&quot;#ffd700&quot; stroke=&quot;#ffd700&quot; points=&quot;252.1053,-128.1579 211.8947,-128.1579 211.8947,-87.9473 252.1053,-87.9473 252.1053,-128.1579&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;232&quot; y=&quot;-103.8526&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot; fill=&quot;#000000&quot;&gt;eth1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- nd_br0_node01&amp;#45;&amp;#45;nd_eth1_vma --&gt;
&lt;g id=&quot;edge4&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;nd_br0_node01--nd_eth1_vma&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;#000000&quot; d=&quot;M209.7261,-168.6166C214.1768,-156.5147 220.015,-140.6405 224.5976,-128.18&quot; /&gt;
&lt;/g&gt;
&lt;!-- nd_eth1_node01&amp;#45;&amp;#45;nd_br1_kubevirtci --&gt;
&lt;g id=&quot;edge1&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;nd_eth1_node01--nd_br1_kubevirtci&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;#000000&quot; d=&quot;M156.2385,-87.8174C146.4655,-76.6833 134.4366,-62.9792 124.9632,-52.1864&quot; /&gt;
&lt;/g&gt;
&lt;!-- nd_br0_node02 --&gt;
&lt;g id=&quot;node5&quot; class=&quot;node&quot;&gt;
&lt;title&gt;nd_br0_node02&lt;/title&gt;
&lt;polygon fill=&quot;#ffd700&quot; stroke=&quot;#ffd700&quot; points=&quot;91,-204.9052 55,-204.9052 55,-168.9052 91,-168.9052 91,-204.9052&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;73&quot; y=&quot;-182.7052&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot; fill=&quot;#000000&quot;&gt;br0&lt;/text&gt;
&lt;/g&gt;
&lt;!-- nd_eth1_node02 --&gt;
&lt;g id=&quot;node6&quot; class=&quot;node&quot;&gt;
&lt;title&gt;nd_eth1_node02&lt;/title&gt;
&lt;polygon fill=&quot;#ffd700&quot; stroke=&quot;#ffd700&quot; points=&quot;64.1053,-128.1579 23.8947,-128.1579 23.8947,-87.9473 64.1053,-87.9473 64.1053,-128.1579&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;44&quot; y=&quot;-103.8526&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot; fill=&quot;#000000&quot;&gt;eth1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- nd_br0_node02&amp;#45;&amp;#45;nd_eth1_node02 --&gt;
&lt;g id=&quot;edge5&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;nd_br0_node02--nd_eth1_node02&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;#000000&quot; d=&quot;M66.2739,-168.6166C61.8232,-156.5147 55.985,-140.6405 51.4024,-128.18&quot; /&gt;
&lt;/g&gt;
&lt;!-- nd_eth1_vmb --&gt;
&lt;g id=&quot;node7&quot; class=&quot;node&quot;&gt;
&lt;title&gt;nd_eth1_vmb&lt;/title&gt;
&lt;polygon fill=&quot;#ffd700&quot; stroke=&quot;#ffd700&quot; points=&quot;122.1053,-128.1579 81.8947,-128.1579 81.8947,-87.9473 122.1053,-87.9473 122.1053,-128.1579&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;102&quot; y=&quot;-103.8526&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot; fill=&quot;#000000&quot;&gt;eth1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- nd_br0_node02&amp;#45;&amp;#45;nd_eth1_vmb --&gt;
&lt;g id=&quot;edge6&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;nd_br0_node02--nd_eth1_vmb&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;#000000&quot; d=&quot;M79.7261,-168.6166C84.1768,-156.5147 90.015,-140.6405 94.5976,-128.18&quot; /&gt;
&lt;/g&gt;
&lt;!-- nd_eth1_node02&amp;#45;&amp;#45;nd_br1_kubevirtci --&gt;
&lt;g id=&quot;edge2&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;nd_eth1_node02--nd_br1_kubevirtci&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;#000000&quot; d=&quot;M61.7615,-87.8174C71.5345,-76.6833 83.5634,-62.9792 93.0368,-52.1864&quot; /&gt;
&lt;/g&gt;
&lt;/g&gt;
&lt;/svg&gt;

&lt;!-- NOTE: When gnudot is at production use proper liquid tags to use this code --&gt;
&lt;!--
graph bridge {
node [shape=square, style=filled color=gold];
splines=line;
subgraph cluster_kubevirtci {
label = &quot;kubevirtci cluster&quot;;
color = mediumseagreen;
style = filled;
nd_br1_kubevirtci [label = &quot;br1&quot;]
subgraph cluster_node01 {
label = &quot;node01&quot;;
color = khaki4;
style=filled;
nd_br0_node01 [label = &quot;br0&quot;]
nd_eth1_node01 [label = &quot;eth1&quot;]
subgraph cluster_vma {
label = &quot;vma&quot;;
style=filled;
color=lightcyan3;
nd_eth1_vma [label = &quot;eth1&quot;];
}

    }
    subgraph cluster_node02 {
      label = &quot;node02&quot;;
      color = khaki4;
      style = filled;
      nd_br0_node02 [label = &quot;br0&quot;]
      nd_eth1_node02 [label = &quot;eth1&quot;]
      subgraph cluster_vmb {
        label = &quot;vmb&quot;;
        style=filled;
        color=lightcyan3;
        nd_eth1_vmb [label = &quot;eth1&quot;];
      }

    }
    nd_eth1_node01 -- nd_br1_kubevirtci
    nd_eth1_node02 -- nd_br1_kubevirtci
    nd_br0_node01 -- nd_eth1_node01
    nd_br0_node01 -- nd_eth1_vma
    nd_br0_node02 -- nd_eth1_node02
    nd_br0_node02 -- nd_eth1_vmb

}
}
--&gt;

&lt;!-- yaspeller ignore:end --&gt;

&lt;p&gt;First step is to install the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;virtctl&lt;/code&gt; command line tool to play with virtual machines:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl &lt;span class=&quot;nt&quot;&gt;-L&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; virtctl https://github.com/kubevirt/kubevirt/releases/download/v0.33.0/virtctl-v0.33.0-linux-amd64
&lt;span class=&quot;nb&quot;&gt;chmod&lt;/span&gt; +x virtctl
&lt;span class=&quot;nb&quot;&gt;sudo install &lt;/span&gt;virtctl /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now let’s create two &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VirtualMachine&lt;/code&gt;s on each node. They will have one secondary NIC connected to br0 using the multus configuration for vlan 100. We will also activate kubemacpool to be sure that mac addresses are unique in the cluster and install the qemu-guest-agent so IP addresses from secondary NICs are reported to VM and we can inspect them later on.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;cat &amp;lt;&amp;lt;EOF | kubectl apply -f -&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Namespace&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;mutatevirtualmachines.kubemacpool.io&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;allocate&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kubevirt.io/v1alpha3&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachine&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vma&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;running&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;nodeSelector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;kubernetes.io/hostname&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;node01&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;devices&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;disks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;containerdisk&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;interfaces&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;masquerade&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;br0-100&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;bridge&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;machine&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1024M&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;pod&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;br0-100&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;multus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;networkName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;br0-100-l2&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;terminationGracePeriodSeconds&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;containerdisk&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;containerDisk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kubevirt/fedora-cloud-container-disk-demo&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;cloudInitNoCloud&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;networkData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;version: 2&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;ethernets:&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;eth1:&lt;/span&gt;
                  &lt;span class=&quot;s&quot;&gt;addresses: [ 10.200.0.1/24 ]&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|-&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;#!/bin/bash&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;echo &quot;fedora&quot; |passwd fedora --stdin&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;dnf -y install qemu-guest-agent&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;sudo systemctl enable qemu-guest-agent&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;sudo systemctl start qemu-guest-agent&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kubevirt.io/v1alpha3&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachine&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vmb&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;running&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;nodeSelector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;kubernetes.io/hostname&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;node02&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;devices&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;disks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;containerdisk&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;interfaces&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;masquerade&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;br0-100&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;bridge&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;machine&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1024M&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;pod&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;br0-100&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;multus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;networkName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;br0-100-l2&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;terminationGracePeriodSeconds&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;containerdisk&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;containerDisk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kubevirt/fedora-cloud-container-disk-demo&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;cloudInitNoCloud&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;networkData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;version: 2&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;ethernets:&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;eth1:&lt;/span&gt;
                  &lt;span class=&quot;s&quot;&gt;addresses: [ 10.200.0.2/24 ]&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|-&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;#!/bin/bash&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;echo &quot;fedora&quot; |passwd fedora --stdin&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;dnf -y install qemu-guest-agent&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;sudo systemctl enable qemu-guest-agent&lt;/span&gt;
              &lt;span class=&quot;s&quot;&gt;sudo systemctl start qemu-guest-agent&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Wait for the two VMs to be ready.
Eventually you will see something like this:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get vmi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;NAME      AGE    PHASE     IP               NODENAME
vma      2m4s   Running   10.244.196.142   node01
vmb      2m4s   Running   10.244.140.86    node02
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can check that they have one secondary NIC without
address assigned:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get vmi &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;## vma&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;interfaces&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;interfaceName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;eth0&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ipAddress&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10.244.196.144&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ipAddresses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10.244.196.144&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fd10:244::c48f&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;mac&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;02:4a:be:00:00:0a&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;interfaceName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;eth1&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ipAddress&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10.200.0.1/24&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ipAddresses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10.200.0.1/24&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fe80::4a:beff:fe00:b/64&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;mac&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;02:4a:be:00:00:0b&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;br0-100&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## vmb&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;interfaces&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;interfaceName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;eth0&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ipAddress&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10.244.140.84&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ipAddresses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10.244.140.84&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fd10:244::8c53&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;mac&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;02:4a:be:00:00:0e&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;interfaceName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;eth1&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ipAddress&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10.200.0.2/24&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ipAddresses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10.200.0.2/24&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fe80::4a:beff:fe00:f/64&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;mac&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;02:4a:be:00:00:0f&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;br0-100&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let’s finish this section by verifying connectivity between vma and vmb using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ping&lt;/code&gt;. Open the console of vma virtual machine and use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ping&lt;/code&gt; command with destination IP address 10.200.0.2, which is the address assigned to the secondary interface of vmb:&lt;/p&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;The user and password for this VMs is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fedora&lt;/code&gt;, it was configured at cloudinit userData&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;virtctl console vma
ping 10.200.0.2 &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; 3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PING 10.200.0.2 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;10.200.0.2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: 56 data bytes
64 bytes from 10.200.0.2: &lt;span class=&quot;nb&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &lt;span class=&quot;nv&quot;&gt;ttl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;50 &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;357.040 ms
64 bytes from 10.200.0.2: &lt;span class=&quot;nb&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1 &lt;span class=&quot;nv&quot;&gt;ttl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;50 &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;379.742 ms
64 bytes from 10.200.0.2: &lt;span class=&quot;nb&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2 &lt;span class=&quot;nv&quot;&gt;ttl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;50 &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;404.066 ms

&lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt; 10.200.0.2 ping statistics &lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 357.040/380.282/404.066 ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this blog post we used network components from KubeVirt project to connect two VMs on different nodes
through a linux bridge connected to a secondary NIC. This illustrates how VM traffic can be directed to a specific NIC
on a node using a secondary NIC on a VM.&lt;/p&gt;</content><author><name>ellorent</name></author><category term="news" /><category term="kubevirt-hyperconverged" /><category term="cnao" /><category term="cluster-network-addons-operator" /><category term="kubernetes-nmstate" /><category term="nmstate" /><category term="bridge" /><category term="multus" /><category term="networking" /><category term="CNI" /><category term="multiple networks" /><summary type="html">Introduction</summary></entry><entry><title type="html">Import virtual machine from oVirt</title><link href="https://kubevirt.io//2020/Import-VM-from-oVirt.html" rel="alternate" type="text/html" title="Import virtual machine from oVirt" /><published>2020-08-06T00:00:00+00:00</published><updated>2020-08-06T00:00:00+00:00</updated><id>https://kubevirt.io//2020/Import-VM-from-oVirt</id><content type="html" xml:base="https://kubevirt.io//2020/Import-VM-from-oVirt.html">&lt;h2 id=&quot;about-vm-import-operator&quot;&gt;About vm-import-operator&lt;/h2&gt;
&lt;p&gt;Virtual machine import operator makes life easier for users who want to migrate their virtual machine workload from different infrastructures to KubeVirt. Currently the operator supports migration from oVirt only. The operator is configurable so user can define how the storage or network should be mapped. For the disk import vm import operator is using the &lt;a href=&quot;https://github.com/kubevirt/containerized-data-importer&quot;&gt;CDI&lt;/a&gt;, so in order to have the vm import working you must have both KubeVirt and CDI installed.&lt;/p&gt;

&lt;h3 id=&quot;import-rules&quot;&gt;Import rules&lt;/h3&gt;
&lt;p&gt;Before the import process is initiated we run validation of the source VM, to be sure the KubeVirt will run the source VM smoothly. We have many &lt;a href=&quot;https://github.com/kubevirt/vm-import-operator/blob/master/docs/rules.md&quot;&gt;rules&lt;/a&gt; defined including storage, network and the VM. You will see all warning messages in the conditions field. For example:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;lastHeartbeatTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-11T11:13:31Z&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;lastTransitionTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-11T11:13:31Z&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;VM&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;specifies&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;IO&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Threads:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1,&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;VM&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;NUMA&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;tune&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;secified:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;interleave'&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;reason&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MappingRulesVerificationReportedWarnings&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;True&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MappingRulesVerified&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;supported-guest-operating-systems&quot;&gt;Supported Guest Operating Systems&lt;/h3&gt;
&lt;p&gt;We support following guest operating systems:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Red Hat Enterprise Linux 6&lt;/li&gt;
  &lt;li&gt;Red Hat Enterprise Linux 7&lt;/li&gt;
  &lt;li&gt;Red Hat Enterprise Linux 8&lt;/li&gt;
  &lt;li&gt;Microsoft Windows 10&lt;/li&gt;
  &lt;li&gt;Microsoft Windows Server 2012r2&lt;/li&gt;
  &lt;li&gt;Microsoft Windows Server 2016&lt;/li&gt;
  &lt;li&gt;Microsoft Windows Server 2019&lt;/li&gt;
  &lt;li&gt;CentOS Linux 6&lt;/li&gt;
  &lt;li&gt;CentOS Linux 7&lt;/li&gt;
  &lt;li&gt;CentOS Linux 8&lt;/li&gt;
  &lt;li&gt;Ubuntu 18.04&lt;/li&gt;
  &lt;li&gt;Fedora&lt;/li&gt;
  &lt;li&gt;openSUSE&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;setup-vm-import-operator&quot;&gt;Setup vm-import-operator&lt;/h2&gt;
&lt;p&gt;Source code for virtual machine import operator is hosted on github under &lt;a href=&quot;https://github.com/kubevirt&quot;&gt;KubeVirt&lt;/a&gt; organization. You can very easily deploy it on your Kubernetes by running following commands:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://github.com/kubevirt/vm-import-operator/releases/download/v0.1.0/namespace.yaml
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://github.com/kubevirt/vm-import-operator/releases/download/v0.1.0/operator.yaml
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://github.com/kubevirt/vm-import-operator/releases/download/v0.1.0/vmimportconfig_cr.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By default the operator is deployed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kubevirt-hyperconverged&lt;/code&gt; namespace,
you can verify that the operator is deployed and running by running:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get deploy vm-import-controller &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; kubevirt-hyperconverged
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you are using &lt;a href=&quot;https://github.com/kubevirt/hyperconverged-cluster-operator/&quot;&gt;HCO&lt;/a&gt;, you don’t have to install it manually,
because the HCO takes care of that.&lt;/p&gt;

&lt;h2 id=&quot;importing-virtual-machine-from-ovirt&quot;&gt;Importing virtual machine from oVirt&lt;/h2&gt;
&lt;p&gt;In order to import a virtual machine from oVirt user must obtain credentials for the oVirt environment. oVirt environment is usually accessed using username, password and http URL. Note that you must provide CA certificate of your oVirt environment. If you have those - create a secret out of them:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Secret&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ovirt-secret&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Opaque&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;stringData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;ovirt&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|-&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;apiUrl: https://engine-url/ovirt-engine/api&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;username: admin@internal&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;password: &quot;secretpassword&quot;&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;caCert: |&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;-----BEGIN CERTIFICATE-----&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;MIIEMjCCAxqgAwIBAgICEAAwDQYJKoZIhvcNAQELBQAwbDELMAkGA1UEBhMCVVMxJDAiBgNVBAoM&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;....&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;fFyt91ClrUtTE707IFnYdQQUiZ4zI0q+6pmw6+xx8mH5k8Ad6D71pF718xCM1NiBx/Cusg==&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;-----END CERTIFICATE-----&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Another step to initiate the import is creating the mappings. The mappings has three categories - storage mapping, disk mapping and network mapping. For storage mapping user can define which oVirt storage domain will be mapped to which storage class. Disk mapping can override the storage mapping for specific disks. The network mappings map oVirt network to the kubernetes network. So here an simple example of mapping:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v2v.kubevirt.io/v1alpha1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ResourceMapping&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myvm-mapping&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;ovirt&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;networkMappings&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ovirtmgmt/ovirtmgmt&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;pod&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;pod&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;storageMappings&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mystoragedomain&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mystorageclass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above mapping maps &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ovirtmgmt/ovirtmgmt&lt;/code&gt; which is in format of vNIC profile/network to the pod network and disks from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mystoragedomain&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mystorageclass&lt;/code&gt;. Once we have mapping and the secret, we can initiate the import by creating a VM import CR. You must provide the name of the mapping, secret, source VM and target VM name.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v2v.kubevirt.io/v1alpha1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachineImport&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myvm&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;providerCredentialsSecret&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ovirt-secret&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;resourceMapping&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myvm-mapping&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;targetVmName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;testvm&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;na&quot;&gt;ovirt&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
     &lt;span class=&quot;na&quot;&gt;vm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
       &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myvm&lt;/span&gt;
       &lt;span class=&quot;na&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
         &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mycluster&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that it is also possible to use internal mappings, so the user can create the mappings inside the VM import CR, for example:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v2v.kubevirt.io/v1alpha1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachineImport&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myvm&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;providerCredentialsSecret&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ovirt-secret&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;targetVmName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;testvm&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ovirt&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;mappings&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;networkMappings&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ovirtmgmt/ovirtmgmt&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;pod&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;pod&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;storageMappings&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mystoragedomain&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mystorageclass&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;vm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myvm&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mycluster&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now let the operator do its work. You can explore the status by checking the status of the VM import CR&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;conditions&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;lastHeartbeatTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:09:22Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;lastTransitionTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:09:22Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Validation completed successfully&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;reason&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ValidationCompleted&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;True&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Valid&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;lastHeartbeatTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:09:22Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;lastTransitionTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:09:22Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;VM&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;specifies&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;IO&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Threads:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1,&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;VM&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;has&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;NUMA&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;tune&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;secified:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;interleave'&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;reason&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MappingRulesVerificationReportedWarnings&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;True&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MappingRulesVerified&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;lastHeartbeatTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:10:29Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;lastTransitionTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:09:22Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Copying virtual machine disks&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;reason&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ProcessingCompleted&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;True&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Processing&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;lastHeartbeatTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:10:29Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;lastTransitionTime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2020-08-05T13:10:29Z&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Virtual machine disks import done&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;reason&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachineReady&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;True&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Succeeded&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;dataVolumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;testvm-26097887-1f4d-4718-961f-f5b63a49c3f5&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;targetVmName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;testvm&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The import process goes through different stages. The first stage is the validation where HCO checks for unsupported mappings.
The others are for processing and reporting to provide VM and disks ready status.&lt;/p&gt;

&lt;h2 id=&quot;future&quot;&gt;Future&lt;/h2&gt;
&lt;p&gt;For future releases it is planned to support importing virtual machines from VMware, reporting Prometheus metrics and SR-IOV.&lt;/p&gt;</content><author><name>Ondra Machacek</name></author><category term="news" /><category term="kubevirt" /><category term="Kubernetes" /><category term="virtual machine" /><category term="VM" /><category term="import" /><category term="oVirt" /><summary type="html">About vm-import-operator Virtual machine import operator makes life easier for users who want to migrate their virtual machine workload from different infrastructures to KubeVirt. Currently the operator supports migration from oVirt only. The operator is configurable so user can define how the storage or network should be mapped. For the disk import vm import operator is using the CDI, so in order to have the vm import working you must have both KubeVirt and CDI installed.</summary></entry><entry><title type="html">Minikube KubeVirt addon</title><link href="https://kubevirt.io//2020/Minikube_KubeVirt_Addon.html" rel="alternate" type="text/html" title="Minikube KubeVirt addon" /><published>2020-07-20T00:00:00+00:00</published><updated>2020-07-20T00:00:00+00:00</updated><id>https://kubevirt.io//2020/Minikube_KubeVirt_Addon</id><content type="html" xml:base="https://kubevirt.io//2020/Minikube_KubeVirt_Addon.html">&lt;h2 id=&quot;deploying-kubevirt-has-just-gotten-easier&quot;&gt;Deploying KubeVirt has just gotten easier!&lt;/h2&gt;
&lt;p&gt;With the latest release (v1.12) of
&lt;a href=&quot;https://minikube.sigs.k8s.io/docs/&quot;&gt;minikube&lt;/a&gt; we can now deploy KubeVirt with
a one-liner.&lt;/p&gt;

&lt;h2 id=&quot;deploy-minikube&quot;&gt;Deploy minikube&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Start minikube.  Since my host is Fedora 32 I will use --driver=kvm2 and
  I will also use --container-runtime=crio&lt;br /&gt;
    &lt;code&gt;minikube start --driver=kvm2 --container-runtime=cri-o&lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-07-20-Minikube_KubeVirt_Addon/1.png&quot; width=&quot;115&quot; height=&quot;72&quot; itemprop=&quot;thumbnail&quot; alt=&quot;minikube start&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Check that kubectl client is working correctly&lt;br /&gt;
    &lt;code&gt;kubectl cluster-info&lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-07-20-Minikube_KubeVirt_Addon/2.png&quot; width=&quot;115&quot; height=&quot;11&quot; itemprop=&quot;thumbnail&quot; alt=&quot;kubectl cluster-info&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Enable the minikube kubevirt addon&lt;br /&gt;
    &lt;code&gt;minikube addons enable kubevirt&lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-07-20-Minikube_KubeVirt_Addon/3.png&quot; width=&quot;115&quot; height=&quot;10&quot; itemprop=&quot;thumbnail&quot; alt=&quot;minikube addons enable kubevirt&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Verify KubeVirt components have been deployed to the kubevirt namespace&lt;br /&gt;
    &lt;code&gt;kubectl get ns; kubectl get all -n kubevirt&lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-07-20-Minikube_KubeVirt_Addon/4.png&quot; width=&quot;115&quot; height=&quot;77&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Verify KubeVirt namespace and components&quot; /&gt;
    &lt;/div&gt;
  &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;success&quot;&gt;SUCCESS!&lt;/h3&gt;

&lt;p&gt;From here a user can proceed on to the
&lt;a href=&quot;/labs/kubernetes/lab1&quot;&gt;Kubevirt Laboratory 1: Use KubeVirt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;As you can see it is now much easier to deploy KubeVirt in a minikube
Kubernetes environment.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Chris Callegari</name></author><category term="news" /><category term="kubevirt" /><category term="Kubernetes" /><category term="virtual machine" /><category term="VM" /><category term="minikube" /><category term="addons" /><summary type="html">Deploying KubeVirt has just gotten easier! With the latest release (v1.12) of minikube we can now deploy KubeVirt with a one-liner.</summary></entry><entry><title type="html">Common-templates</title><link href="https://kubevirt.io//2020/Common_templates.html" rel="alternate" type="text/html" title="Common-templates" /><published>2020-07-01T00:00:00+00:00</published><updated>2020-07-01T00:00:00+00:00</updated><id>https://kubevirt.io//2020/Common_templates</id><content type="html" xml:base="https://kubevirt.io//2020/Common_templates.html">&lt;h2 id=&quot;what-is-a-virtual-machine-template&quot;&gt;What is a virtual machine template?&lt;/h2&gt;

&lt;p&gt;The KubeVirt project provides a set of templates (https://github.com/kubevirt/common-templates) to create VMS to handle common usage scenarios. These templates provide a combination of some key factors that could be further customized and processed to have a Virtual Machine object. With common templates you can easily start in a few minutes many VMS with predefined hardware resources (e.g. number of CPUs, requested memory, etc.).&lt;/p&gt;

&lt;div class=&quot;premonition warning&quot;&gt;&lt;div class=&quot;fa fa-exclamation-circle&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Beware&lt;/p&gt;&lt;p&gt;common templates work only on OpenShift. Kubernetes doesn’t have support for templates.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;what-does-a-vm-template-cover&quot;&gt;What does a VM template cover?&lt;/h2&gt;

&lt;p&gt;The key factors which define a template are&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Guest Operating System (OS) This allows to ensure that the emulated hardware is compatible with the guest OS. Furthermore, it allows to maximize the stability of the VM, and allows performance optimizations. Currently common templates support RHEL 6, 7, 8, Centos 6, 7, 8, Fedora 31 and newer, Windows 10, Windows server 2008, 2012 R2, 2016, 2019. The &lt;a href=&quot;https://docs.ansible.com/ansible/latest/user_guide/playbooks.html&quot;&gt;Ansible playbook&lt;/a&gt; &lt;a href=&quot;https://github.com/kubevirt/common-templates/blob/master/generate-templates.yaml&quot;&gt;generate-templates.yaml&lt;/a&gt; describes all combinations of templates that should be generated.&lt;/li&gt;
  &lt;li&gt;Workload type of most virtual machines should be server or desktop to have maximum flexibility; the highperformance workload trades some of this flexibility (ioThreadsPolicy is set to shared) to provide better performances (e.g. IO threads).&lt;/li&gt;
  &lt;li&gt;Size (flavor) Defines the amount of resources (CPU, memory) to allocate to the VM. There are 4 sizes: tiny (1 core, 1 Gi memory), small (1 core, 2 Gi memory), medium (1 core, 4 Gi memory), large (2 cores, 8 Gi memory). If these predefined sizes don’t suit you, you can create a new template based on common templates via UI (choose &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Workloads&lt;/code&gt; in the left panel » press &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Virtualization&lt;/code&gt; » press &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Virtual Machine Templates&lt;/code&gt; » press &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Create Virtual Machine Template&lt;/code&gt; blue button) or CLI (update yaml template and create new template).&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;zoom&quot;&gt;
  &lt;img src=&quot;/assets/2020-07-01-Common_templates/create_template.jpg&quot; width=&quot;100&quot; height=&quot;60&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Create new template&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;accessing-the-virtual-machine-templates&quot;&gt;Accessing the virtual machine templates&lt;/h2&gt;
&lt;p&gt;If you installed KubeVirt using a &lt;a href=&quot;https://github.com/kubevirt/hyperconverged-cluster-operator&quot;&gt;supported method&lt;/a&gt;, you should find the common templates preinstalled in the cluster. If you want to upgrade the templates, or install them from scratch, you can use one of the &lt;a href=&quot;https://github.com/kubevirt/common-templates/releases&quot;&gt;supported releases&lt;/a&gt;
There are two ways to install and configure templates:&lt;/p&gt;

&lt;h2 id=&quot;via-cli&quot;&gt;Via CLI:&lt;/h2&gt;

&lt;h6 id=&quot;to-install-the-templates&quot;&gt;To install the templates:&lt;/h6&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ export VERSION=&quot;v0.11.2&quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ oc create -f https://github.com/kubevirt/common-templates/releases/download/$VERSION/common-templates-$VERSION.yaml&lt;/code&gt;&lt;/p&gt;

&lt;h6 id=&quot;to-create-vm-from-template&quot;&gt;To create VM from template:&lt;/h6&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ oc process rhel8-server-tiny PVCNAME=mydisk NAME=rheltinyvm | oc apply -f -&lt;/code&gt;&lt;/p&gt;

&lt;h6 id=&quot;to-start-vm-from-created-object&quot;&gt;To start VM from created object:&lt;/h6&gt;
&lt;p&gt;The created object is now a regular VirtualMachine object and from now it can be controlled by accessing Kubernetes API resources. The preferred way to do this is to use virtctl tool.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ virtctl start rheltinyvm&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;An alternative way to start the VM is with the oc patch command. Example:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ oc patch virtualmachine rheltinyvm --type merge -p '{&quot;spec&quot;:{&quot;running&quot;:true}}'&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;As soon as VM starts, openshift creates a new type of object - &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VirtualMachineInstance&lt;/code&gt;. It has a similar name to VirtualMachine.&lt;/p&gt;

&lt;h2 id=&quot;via-ui&quot;&gt;Via UI:&lt;/h2&gt;
&lt;p&gt;The Kubevirt project has an official plugin in OpenShift Cluster Console Web UI. This UI supports the creation of VMS using templates and template features - flavors and workload profiles.&lt;/p&gt;

&lt;h6 id=&quot;to-install-the-templates-1&quot;&gt;To install the templates:&lt;/h6&gt;

&lt;p&gt;Install OpenShift virtualization operator from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Operators&lt;/code&gt; &amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OperatorHub&lt;/code&gt;. The operator-based deployment takes care of installing various components, including the common templates.&lt;/p&gt;

&lt;div class=&quot;zoom&quot;&gt;
  &lt;img src=&quot;/assets/2020-07-01-Common_templates/operator.jpg&quot; width=&quot;100&quot; height=&quot;60&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Install operator&quot; /&gt;
&lt;/div&gt;

&lt;h6 id=&quot;to-create-vm-from-template-1&quot;&gt;To create VM from template:&lt;/h6&gt;
&lt;p&gt;To create a VM from a template, choose &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Workloads&lt;/code&gt; in the left panel » press &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Virtualization&lt;/code&gt; » press &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Create Virtual Machine&lt;/code&gt; blue button » choose &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;New with Wizard&lt;/code&gt;. Next, you have to see &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Create Virtual Machine&lt;/code&gt; window&lt;/p&gt;

&lt;div class=&quot;zoom&quot;&gt;
  &lt;img src=&quot;/assets/2020-07-01-Common_templates/create_vm.jpg&quot; width=&quot;100&quot; height=&quot;60&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Create vm from template&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;This wizard leads you through the basic setup of vm (like guest operating system, workload, flavor, …). After vm is created you can start requested vm.&lt;/p&gt;

&lt;div class=&quot;premonition note&quot;&gt;&lt;div class=&quot;fa fa-check-square&quot;&gt;&lt;/div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p class=&quot;header&quot;&gt;Note&lt;/p&gt;&lt;p&gt;after the generation step (UI and CLI), VM objects and template objects have no relationship with each other besides the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vm.kubevirt.io/template: rhel8-server-tiny-v0.10.0&lt;/code&gt; label. This means that changes in templates do not automatically affect VMS, or vice versa.&lt;/p&gt;


&lt;/div&gt;&lt;/div&gt;</content><author><name>Karel Simon</name></author><category term="news" /><category term="kubevirt" /><category term="Kubernetes" /><category term="virtual machine" /><category term="VM" /><category term="common-templates" /><summary type="html">What is a virtual machine template?</summary></entry><entry><title type="html">Migrate a sample Windows workload to Kubernetes using KubeVirt and CDI</title><link href="https://kubevirt.io//2020/win_workload_in_k8s.html" rel="alternate" type="text/html" title="Migrate a sample Windows workload to Kubernetes using KubeVirt and CDI" /><published>2020-06-22T00:00:00+00:00</published><updated>2020-06-22T00:00:00+00:00</updated><id>https://kubevirt.io//2020/win_workload_in_k8s</id><content type="html" xml:base="https://kubevirt.io//2020/win_workload_in_k8s.html">&lt;p&gt;The goal of this blog is to demonstrate that a web service can continue to run
after a Windows guest virtual machine providing the service is migrated from
MS Windows and Oracle VirtualBox to a guest virtual machine orchestrated by
Kubernetes and KubeVirt on a Fedora Linux host.  Yes!  It can be done!&lt;/p&gt;

&lt;h3 id=&quot;source-details&quot;&gt;Source details&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Host platform: Windows 2019 Datacenter&lt;/li&gt;
  &lt;li&gt;Virtualization platform: Oracle VirtualBox 6.1&lt;/li&gt;
  &lt;li&gt;Guest platform: Windows 2019 Datacenter (guest to be migrated)
&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;
&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;
&lt;/sup&gt;&lt;/li&gt;
  &lt;li&gt;Guest application: My favorite dotnet application
&lt;a href=&quot;https://jellyfin.org/&quot;&gt;Jellyfin&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;target-details&quot;&gt;Target details&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Host platform: Fedora 32 with latest updates applied&lt;/li&gt;
  &lt;li&gt;Kubernetes cluster created&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://kubevirt.io/quickstart_minikube/&quot;&gt;KubeVirt&lt;/a&gt; and &lt;a href=&quot;https://kubevirt.io/user-guide/#/installation/image-upload&quot;&gt;CDI&lt;/a&gt; installed in the Kubernetes cluster.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;procedure&quot;&gt;Procedure&lt;/h2&gt;

&lt;h3 id=&quot;tasks-to-performed-on-source-host&quot;&gt;Tasks to performed on source host&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Before we begin let's take a moment to ensure the service is running and
  web browser accessible&lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/1-1.png&quot; width=&quot;100&quot; height=&quot;60&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Ensure application service is running&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/1-2.png&quot; width=&quot;100&quot; height=&quot;60&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Confirm web browser access&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Power down the guest virtual machine to ensure all changes to the
  filesystem are quiesced to disk.&lt;br /&gt;
    &lt;code&gt;VBoxManage.exe controlvm testvm poweroff&lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/1-3.png&quot; width=&quot;115&quot; height=&quot;20&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Power down the guest virtual machine&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Upload the guest virtual machine disk image to the Kubernetes cluster
  and a target DataVolume called testvm
    &lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;
      &lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;
    &lt;/sup&gt;
    &lt;br /&gt;
    &lt;code&gt;
      virtctl.exe image-upload dv testvm
      --size=14Gi
      --image-path=&quot;C:\Users\Administrator\VirtualBox VMs\testvm\testvm.vdi&quot;
    &lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/1-4.png&quot; width=&quot;100&quot; height=&quot;60&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Upload disk image&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Verify the PersistentVolumeClaim created via the DataVolume
  image upload in the previous step&lt;br /&gt;
    &lt;code&gt;
      kubectl describe pvc/testvm
    &lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/2-1.png&quot; width=&quot;125&quot; height=&quot;75&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Verify PersistentVolumeClaim&quot; /&gt;
    &lt;/div&gt;
  &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Create a guest virtual machine definition that references the
  DataVolume containing our guest virtual machine disk image&lt;br /&gt;
    &lt;code&gt;kubectl create -f vm_testvm.yaml&lt;/code&gt;
    &lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;
      &lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;
    &lt;/sup&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/2-2.png&quot; width=&quot;125&quot; height=&quot;75&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Create the guest virtual machine&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Expose the Jellyfin service in Kubernetes via a NodePort type
  service&lt;br /&gt;
    &lt;code&gt;
      kubectl create -f service_jellyfin.yaml
    &lt;/code&gt;
    &lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;
      &lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;
    &lt;/sup&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/2-3.png&quot; width=&quot;100&quot; height=&quot;75&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Create NodePort service&quot; /&gt;
    &lt;/div&gt;
  &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;&lt;li&gt;Let's verify the running guest virtual machine by using the virtctl
  command to open a vnc session to the MS Window console.  While we are here
  let's also open a web browser and confirm web browser access to the
  application.&lt;br /&gt;
    &lt;code&gt;virtctl vnc testvm&lt;/code&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/2-4.png&quot; width=&quot;125&quot; height=&quot;70&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Verify running guest virtual machine&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/2-5.png&quot; width=&quot;125&quot; height=&quot;70&quot; itemprop=&quot;thumbnail&quot; alt=&quot;Web browser access to application&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;task-to-performed-on-user-workstation&quot;&gt;Task to performed on user workstation&lt;/h3&gt;

&lt;ol&gt;
  And finally let's confirm web browser access via the Kubernetes service url.&lt;br /&gt;
    &lt;div class=&quot;zoom&quot;&gt;
      &lt;img src=&quot;/assets/2020-06-22-win_workload_in_k8s/2-6.png&quot; width=&quot;125&quot; height=&quot;70&quot; alt=&quot;Web browser access to Kubernetes service&quot; /&gt;
    &lt;/div&gt;
    &lt;br /&gt;&lt;br /&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;success&quot;&gt;SUCCESS!&lt;/h3&gt;

&lt;p&gt;Here we have successfully demonstrated how simple it can be to migrate an
existing MS Windows platform and application to Kubernetes control. For
questions feel free to join the conversation via one of the project forums.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h5 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h5&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-noteref&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-noteref&quot;&gt;
      Fedora virtio drivers need to be installed on Windows hosts or virtual
      machines that will be migrated into a Kubernetes environment. Drivers can
      be found
      &lt;a href=&quot;https://docs.fedoraproject.org/en-US/quick-docs/creating-windows-virtual-machines-using-virtio-drivers/&quot;&gt;
        here
      &lt;/a&gt;.
      &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-noteref&quot;&gt;&amp;#8617;&lt;/a&gt;
    &lt;/li&gt;&lt;li id=&quot;fn:2&quot; role=&quot;doc-noteref&quot;&gt;
      Please note:
      &lt;br /&gt;
      &amp;#8226; Users without certificate authority trusted certificates added to
      the kubernetes api and cdi cdi-proxyuploader secret will require the
      &lt;code&gt;--insecure&lt;/code&gt; arg.
      &lt;br /&gt;
      &amp;#8226; Users without the uploadProxyURLOverride patch to the cdi
      cdiconfig.cdi.kubevirt.io/config crd will require the
      &lt;code&gt;--uploadProxyURL&lt;/code&gt; arg.
      &lt;br /&gt;
      &amp;#8226; Users need a correctly configured $HOME/.kube/config along with
      client authentication certificate.
      &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-noteref&quot;&gt;&amp;#8617;&lt;/a&gt;
    &lt;/li&gt;&lt;li id=&quot;fn:3&quot; role=&quot;doc-noteref&quot;&gt;
      &lt;a href=&quot;/assets/2020-06-22-win_workload_in_k8s/vm_testvm.yaml&quot;&gt;
        vm_testvm.yaml
      &lt;/a&gt;: Virtual machine manifest
      &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-noteref&quot;&gt;&amp;#8617;&lt;/a&gt;
    &lt;/li&gt;&lt;li id=&quot;fn:4&quot; role=&quot;doc-noteref&quot;&gt;
      &lt;a href=&quot;/assets/2020-06-22-win_workload_in_k8s/service_jellyfin.yaml&quot;&gt;
        service_jellyfin.yaml
      &lt;/a&gt;: Service manifest
      &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-noteref&quot;&gt;&amp;#8617;&lt;/a&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Chris Callegari</name></author><category term="news" /><category term="kubevirt" /><category term="Kubernetes" /><category term="virtual machine" /><category term="VM" /><category term="images" /><category term="storage" /><category term="windows" /><summary type="html">The goal of this blog is to demonstrate that a web service can continue to run after a Windows guest virtual machine providing the service is migrated from MS Windows and Oracle VirtualBox to a guest virtual machine orchestrated by Kubernetes and KubeVirt on a Fedora Linux host. Yes! It can be done!</summary></entry><entry><title type="html">SELinux, from basics to KubeVirt</title><link href="https://kubevirt.io//2020/SELinux-from-basics-to-KubeVirt.html" rel="alternate" type="text/html" title="SELinux, from basics to KubeVirt" /><published>2020-05-25T00:00:00+00:00</published><updated>2020-05-25T00:00:00+00:00</updated><id>https://kubevirt.io//2020/SELinux-from-basics-to-KubeVirt</id><content type="html" xml:base="https://kubevirt.io//2020/SELinux-from-basics-to-KubeVirt.html">&lt;p&gt;SELinux is one of many security mechanisms leveraged by KubeVirt.&lt;br /&gt;
For an overview of KubeVirt security, please first read &lt;a href=&quot;/2020/KubeVirt-Security-Fundamentals.html&quot;&gt;this excellent article&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;selinux-101&quot;&gt;SELinux 101&lt;/h2&gt;

&lt;p&gt;At its core, SELinux is a whitelist-based security policy system intended to limit interactions between Linux processes and files. Simplified, it can be visualized as a “syscall firewall”.&lt;/p&gt;

&lt;p&gt;Policies are based on statically defined types, that can be assigned to files, processes and other objects.&lt;/p&gt;

&lt;p&gt;A simple policy example would be to allow a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/bin/test&lt;/code&gt; program to read its &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/test.conf&lt;/code&gt; configuration file.&lt;/p&gt;

&lt;p&gt;The policy for that would include directives to:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Assign types to files and processes, like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_bin_t&lt;/code&gt; for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/bin/test&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_conf_t&lt;/code&gt; for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/test.conf&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_t&lt;/code&gt; for instances of the test program&lt;/li&gt;
  &lt;li&gt;Configure a &lt;em&gt;transition&lt;/em&gt; from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_bin_t&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_t&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Allow &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_t&lt;/code&gt; processes to read &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_conf_t&lt;/code&gt; files.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-selinux-standard-reference-policy&quot;&gt;The SELinux standard Reference Policy&lt;/h2&gt;

&lt;p&gt;Since SELinux policies are whitelists, a setup running with the above policy would not be allowed to do anything, except for that test program.&lt;/p&gt;

&lt;p&gt;A policy for an entire Linux distribution as seen in the wild is made of millions of lines, which wouldn’t be practical to write and maintain on a per-distribution basis.&lt;/p&gt;

&lt;p&gt;That is why the &lt;a href=&quot;https://github.com/SELinuxProject/refpolicy&quot;&gt;Reference Policy&lt;/a&gt; (refpolicy) was written. The refpolicy implements various mechanisms to simplify policy writing, but also contains modules for most core Linux applications.&lt;/p&gt;

&lt;p&gt;Most use-cases can be addressed with the “standard” refpolicy, plus optionally some custom modules for specific applications not covered by the Reference Policy.&lt;/p&gt;

&lt;p&gt;Limitations start to arise for use-cases that run the same binary multiple times concurrently, and expect instances to be isolated from each other. Virtualization is one of those use cases. Indeed if 2 virtual machines are running on the same system, it is usually desirable that one VM can’t see the resources of the other one.&lt;/p&gt;

&lt;p&gt;As an example, if qemu processes are labeled &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;qemu_t&lt;/code&gt; and disk files are labeled &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;qemu_disk_t&lt;/code&gt;, allowing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;qemu_t&lt;/code&gt; to read/write &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;qemu_disk_t&lt;/code&gt; files would allow all qemu processes to access all disk files.&lt;/p&gt;

&lt;p&gt;Another mechanism is necessary to provide VM isolation. That is what SELinux MCS addresses.&lt;/p&gt;

&lt;h2 id=&quot;selinux-multi-category-security-mcs&quot;&gt;SELinux Multi-Category Security (MCS)&lt;/h2&gt;

&lt;p&gt;Multi-Category Security, or MCS, provides the ability to dynamically add numerical IDs (called categories) to any SELinux type on any object (file/process/socket/…).&lt;/p&gt;

&lt;p&gt;Categories range from 0 to 1023. Since only 1024 unique IDs would be quite limiting, most virtualization-related applications combine 2 categories, which add up to about 500,000 combinations. It’s important to note that categories have no order, so &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c42,c42&lt;/code&gt; is equivalent to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c42&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c1,c2&lt;/code&gt; is equivalent to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c2,c1&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In the example above, we can now:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Dynamically compute a unique random category for each VM&lt;/li&gt;
  &lt;li&gt;Assign the corresponding categories to all VM resources, like qemu instance and disk files&lt;/li&gt;
  &lt;li&gt;Only allow access when all the involved resources have the same category number.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And that is exactly what libvirt does when compiled with SELinux support, as shown in the diagram below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2020-05-25-SELinux-from-basics-to-KubeVirt/libvirt.svg&quot; alt=&quot;Components View&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note: MCS can do a lot more, this article only describes the bits that are used by libvirt and kubernetes.&lt;/p&gt;

&lt;h3 id=&quot;mcs-and-containers&quot;&gt;MCS and containers&lt;/h3&gt;

&lt;p&gt;Another application that leverages MCS is Linux containers.&lt;/p&gt;

&lt;p&gt;In fact, containers use very few SELinux types and rely mostly on MCS to provide container isolation. For example, all the files and processes in container filesystems have the same SELinux types. For a non-super-privileged container, those types are usually &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;container_file_t&lt;/code&gt; for file and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;container_t&lt;/code&gt; for processes. Most operations are permitted within those types, and the categories are really what matters.&lt;/p&gt;

&lt;p&gt;As with libvirt, categories have to match for access to be granted, effectively blocking inter-container communication.&lt;/p&gt;

&lt;p&gt;Super-privileged containers however are exempt from categories. They use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spc_t&lt;/code&gt; SELinux type, which allows them to do pretty much anything, at least as far as SELinux is concerned.&lt;/p&gt;

&lt;p&gt;That is all defined as an SELinux module in the &lt;a href=&quot;https://github.com/containers/container-selinux&quot;&gt;container-selinux Github repository&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;mcs-and-container-orchestrators&quot;&gt;MCS and container orchestrators&lt;/h3&gt;

&lt;p&gt;Container orchestrators add a level of management. They define pods of containers, and within a pod, cross-container communication is acceptable and often even necessary.&lt;/p&gt;

&lt;p&gt;Categories are therefore managed at the pod level, and all the containers that belong to the same pod are assigned the same categories, as illustrated by the following diagram.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2020-05-25-SELinux-from-basics-to-KubeVirt/kubernetes.svg&quot; alt=&quot;Components View&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;selinux-in-kubevirt&quot;&gt;SELinux in Kubevirt&lt;/h2&gt;

&lt;p&gt;Finally getting to KubeVirt, which relies on all of the above, as it runs libvirt in a container managed by a container orchestrator on SELinux-enabled systems.&lt;/p&gt;

&lt;p&gt;In that context, libvirt runs inside a regular container and can’t manage SELinux object like types and categories. However, MCS isolation is provided by the container orchestrator, and every VM runs in its own pod (virt-launcher). And since no 2 virt-launcher pods will ever have the same categories on a given node, SELinux isolation of VMs is guaranteed.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2020-05-25-SELinux-from-basics-to-KubeVirt/kubevirt.svg&quot; alt=&quot;Components View&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note: As some host configuration is usually required for VMs to run, each node also runs a super-privileged pod (virt-handler), dedicated to such operations.&lt;/p&gt;</content><author><name>Jed Lejosne</name></author><category term="news" /><category term="kubevirt" /><category term="kubernetes" /><category term="virtual machine" /><category term="VM" /><category term="design" /><category term="architecture" /><category term="security" /><category term="libvirt" /><category term="qemu" /><summary type="html">SELinux is one of many security mechanisms leveraged by KubeVirt. For an overview of KubeVirt security, please first read this excellent article.</summary></entry><entry><title type="html">KubeVirt VM Image Usage Patterns</title><link href="https://kubevirt.io//2020/KubeVirt-VM-Image-Usage-Patterns.html" rel="alternate" type="text/html" title="KubeVirt VM Image Usage Patterns" /><published>2020-05-12T00:00:00+00:00</published><updated>2020-05-12T00:00:00+00:00</updated><id>https://kubevirt.io//2020/KubeVirt-VM-Image-Usage-Patterns</id><content type="html" xml:base="https://kubevirt.io//2020/KubeVirt-VM-Image-Usage-Patterns.html">&lt;h1 id=&quot;building-a-vm-image-repository&quot;&gt;Building a VM Image Repository&lt;/h1&gt;

&lt;p&gt;You know what I hear a lot from new KubeVirt users?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“How do I manage VM images with KubeVirt? There’s a million options and I have no idea where to start.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And I agree. It’s not obvious. There are a million ways to use and manipulate VM images with KubeVirt. That’s by design. KubeVirt is meant to be as flexible as possible, but in the process I think we dropped the ball on creating some well defined workflows people can use as a starting point.&lt;/p&gt;

&lt;p&gt;So, that’s what I’m going to attempt to do. I’ll show you how to make your images accessible in the cluster. I’ll show you how to make a custom VM image repository for use within the cluster. And I’ll show you how to use this at scale using the same patterns you may have used in AWS or GCP.&lt;/p&gt;

&lt;p&gt;The pattern we’ll use here is…&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Import a base VM image into the cluster as an PVC&lt;/li&gt;
  &lt;li&gt;Use KubeVirt to create a new immutable custom image with application assets&lt;/li&gt;
  &lt;li&gt;Scale out as many VMIs as we’d like using the pre-provisioned immutable custom image.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Remember, this isn’t “the definitive” way of managing VM images in KubeVirt. This is just an example workflow to help people get started.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;importing-a-base-image&quot;&gt;Importing a Base Image&lt;/h2&gt;

&lt;p&gt;Let’s start with importing a base image into a PVC.&lt;/p&gt;

&lt;p&gt;For our purposes in this workflow, the base image is meant to be immutable. No VM will use this image directly, instead VMs spawn with their own unique copy of this base image. Think of this just like you would containers. A container image is immutable, and a running container instance is using a copy of an image instead of the image itself.&lt;/p&gt;

&lt;h3 id=&quot;step-0-install-kubevirt-with-cdi&quot;&gt;Step 0. Install KubeVirt with CDI&lt;/h3&gt;

&lt;p&gt;I’m not covering this. Use our documentation linked to below. Understand that CDI (containerized data importer) is the tool we’ll be using to help populate and manage PVCs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://kubevirt.io/user-guide/#/installation/installation&quot;&gt;Installing KubeVirt&lt;/a&gt;
&lt;a href=&quot;https://kubevirt.io/user-guide/#/installation/image-upload?id=install-cdi&quot;&gt;Installing CDI&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-1-create-a-namespace-for-our-immutable-vm-images&quot;&gt;Step 1. Create a namespace for our immutable VM images.&lt;/h3&gt;

&lt;p&gt;We’ll give users the ability to clone VM images living on PVCs from this namespace to their own namespace, but not directly create VMIs within this namespace.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create namespace vm-images
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step-2-import-your-image-to-a-pvc-in-the-image-namespace&quot;&gt;Step 2. Import your image to a PVC in the image namespace&lt;/h3&gt;

&lt;p&gt;Below are a few options for importing. For each example, I’m using the Fedora Cloud x86_64 qcow2 image that can be downloaded &lt;a href=&quot;https://alt.fedoraproject.org/cloud/&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you try these examples yourself, you’ll need to download the current Fedora-Cloud-Base qcow2 image file in your working directory.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example: Import a local VM from your desktop environment using virtctl&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If you don’t have ingress setup for the cdi-uploadproxy service endpoint (which you don’t if you’re reading this) we can set up a local port forward using kubectl. That gives a route into the cluster to upload the image. Leave the command below executing to open the port.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl port-forward &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; cdi service/cdi-uploadproxy 18443:443
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In a separate terminal upload the image over the port forward connection using the virtctl tool. Note that the size of the PVC must be the size of what the qcow image will expand to when converted to a raw image. In this case I chose 5 gigabytes as the PVC size.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;virtctl image-upload dv fedora-cloud-base &lt;span class=&quot;nt&quot;&gt;--namespace&lt;/span&gt; vm-images  &lt;span class=&quot;nt&quot;&gt;--size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;5Gi &lt;span class=&quot;nt&quot;&gt;--image-path&lt;/span&gt; Fedora-Cloud-Base-XX-X.X.x86_64.qcow2  &lt;span class=&quot;nt&quot;&gt;--uploadproxy-url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;https://127.0.0.1:18443 &lt;span class=&quot;nt&quot;&gt;--insecure&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once that completes, you’ll have a PVC in the vm-images namespace that contains the Fedora Cloud image.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pvc &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; vm-images
NAME               STATUS   VOLUME              CAPACITY   ACCESS MODES   STORAGECLASS   AGE
fedora-cloud-base   Bound    local-pv-e824538e   5Gi       RWO            &lt;span class=&quot;nb&quot;&gt;local          &lt;/span&gt;60s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Example: Import using a container registry&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If the image’s footprint is small like our Fedora Cloud Base qcow image, then it probably makes sense to use a container image registry to import our image from a container image to a PVC.&lt;/p&gt;

&lt;p&gt;In the example below, I start by building a container image with the Fedora Cloud Base qcow VM image in it, and push that container image to my container registry.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;END&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt; &amp;gt; Dockerfile
FROM scratch
ADD Fedora-Cloud-Base-XX-X.X.x86_64.qcow2 /disk/
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;END
&lt;/span&gt;docker build &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; quay.io/dvossel/fedora:cloud-base &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
docker push quay.io/dvossel/fedora:cloud-base
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next a CDI DataVolume is used to import the VM image into a new PVC from the container image you just uploaded to your container registry. Posting the DataVolume manifest below will result in a new 5 gigabyte PVC being created and the VM image being placed on that PVC in a way KubeVirt can consume it.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;END&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt; &amp;gt; fedora-cloud-base-datavolume.yaml
apiVersion: cdi.kubevirt.io/v1alpha1
kind: DataVolume
metadata:
  name: fedora-cloud-base
  namespace: vm-images
spec:
  source:
    registry:
      url: &quot;docker://quay.io/dvossel/fedora:cloud-base&quot;
  pvc:
    accessModes:
      - ReadWriteOnce
    resources:
      requests:
        storage: 5Gi
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;END
&lt;/span&gt;kubectl create &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; fedora-cloud-base-datavolume.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can observe the CDI complete the import by watching the DataVolume object.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl describe datavolume fedora-cloud-base &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; vm-images
&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
Status:
  Phase:     Succeeded
  Progress:  100.0%
Events:
  Type    Reason            Age                   From                   Message
  &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;    &lt;span class=&quot;nt&quot;&gt;------&lt;/span&gt;            &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;                  &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;                   &lt;span class=&quot;nt&quot;&gt;-------&lt;/span&gt;
  Normal  ImportScheduled   2m49s                 datavolume-controller  Import into fedora-cloud-base scheduled
  Normal  ImportInProgress  2m46s                 datavolume-controller  Import into fedora-cloud-base &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;progress
  Normal  Synced            40s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x11 over 2m51s&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;  datavolume-controller  DataVolume synced successfully
  Normal  ImportSucceeded   40s                   datavolume-controller  Successfully imported into PVC fedora-cloud-base
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once the import is complete, you’ll see the image available as a PVC in your vm-images namespace. The PVC will have the same name given to the DataVolume.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pvc &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; vm-images
NAME                   STATUS   VOLUME              CAPACITY   ACCESS MODES   STORAGECLASS   AGE
fedora-cloud-base   Bound    local-pv-e824538e   5Gi       RWO            &lt;span class=&quot;nb&quot;&gt;local          &lt;/span&gt;60s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Example: Import an image from an http or s3 endpoint&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;While I’m not going to provide a detailed example here, another option for importing VM images into a PVC is to host the image on an http server (or as an s3 object) and then use a DataVolume to import the VM image into the PVC from a URL.&lt;/p&gt;

&lt;p&gt;Replace the url in this example with one hosting the qcow2 image. More information about this import method can be found &lt;a href=&quot;https://github.com/kubevirt/containerized-data-importer/blob/master/doc/datavolumes.md#https3registry-source&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kind: DataVolume
metadata:
  name: fedora-cloud-base
  namespace: vm-images
spec:
  &lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt;:
    http:
      url: http://your-web-server-here/images/Fedora-Cloud-Base-XX-X.X.x86_64.qcow2
  pvc:
    accessModes:
      - ReadWriteOnce
    resources:
      requests:
        storage: 5Gi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;provisioning-new-custom-vm-image&quot;&gt;Provisioning New Custom VM Image&lt;/h2&gt;

&lt;p&gt;The base image itself isn’t that useful to us. Typically what we really want is an immutable VM image preloaded with all our application related assets. This way when the VM boots up, it already has everything it needs pre-provisioned. The pattern we’ll use here is to provision the VM image once, and then use clones of the pre-provisioned VM image as many times as we’d like.&lt;/p&gt;

&lt;p&gt;For this example, I want a new immutable VM image preloaded with an nginx webserver. We can actually describe this entire process of creating this new VM image using the single VM manifest below. Note that I’m starting the VM inside the vm-images namespace. This is because I want the resulting VM image’s cloned PVC to remain in our vm-images repository namespace.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kubevirt.io/v1alpha3&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachine&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;kubevirt.io/vm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-provisioner&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-provisioner&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vm-images&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;runStrategy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;RerunOnFailure&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;kubevirt.io/vm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-provisioner&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;devices&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;disks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;datavolumedisk1&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;machine&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1Gi&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;terminationGracePeriodSeconds&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;dataVolume&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fedora-nginx&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;datavolumedisk1&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;cloudInitNoCloud&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;#!/bin/sh&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;yum install -y nginx&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;systemctl enable nginx&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;# removing instances ensures cloud init will execute again after reboot&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;rm -rf /var/lib/cloud/instances&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;shutdown now&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;dataVolumeTemplates&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fedora-nginx&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;pvc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;accessModes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ReadWriteOnce&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;5Gi&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;pvc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vm-images&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fedora-cloud-base&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There are a few key takeaways from this manifest worth discussing.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Usage of &lt;strong&gt;runStrategy: “RerunOnFailure”&lt;/strong&gt;. This tells KubeVirt to treat the VM’s execution similar to a Kubernetes Job. We want the VM to continue retrying until the VM guest shuts itself down gracefully.&lt;/li&gt;
  &lt;li&gt;Usage of the &lt;strong&gt;cloudInitNoCloud volume&lt;/strong&gt;. This volume allows us to inject a script into the VM’s startup procedure. In our case, we want this script to install nginx, configure nginx to launch on startup, and then immediately shutdown the guest gracefully once that is complete.&lt;/li&gt;
  &lt;li&gt;Usage of the &lt;strong&gt;dataVolumeTemplates section&lt;/strong&gt;. This allows us to define a new PVC which is a clone of our fedora-cloud-base base image. The resulting VM image attached to our VM will be a new image pre-populated with nginx.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After posting the VM manifest to the cluster, wait for the corresponding VMI to reach the Succeeded phase.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get vmi &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; vm-images
NAME                AGE     PHASE       IP            NODENAME
nginx-provisioner   2m26s   Succeeded   10.244.0.22   node01
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This tells us the VM successfully executed the cloud-init script which installed nginx and shut down the guest gracefully. A VMI that never shuts down or repeatedly fails means something is wrong with the provisioning.&lt;/p&gt;

&lt;p&gt;All that’s left now is to delete the VM and leave the resulting PVC behind as our immutable artifact. We do this by deleting the VM using the –cascade=false option. This tells Kubernetes to delete the VM, but leave behind anything owned by the VM. In this case we’ll be leaving behind the PVC that has nginx provisioned on it.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl delete vm nginx-provisioner &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; vm-images &lt;span class=&quot;nt&quot;&gt;--cascade&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After deleting the VM, you can see the nginx provisioned PVC in your vm-images namespace.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get pvc &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; vm-images
NAME               STATUS   VOLUME              CAPACITY   ACCESS MODES   STORAGECLASS   AGE
fedora-cloud-base   Bound    local-pv-e824538e   5Gi       RWO            &lt;span class=&quot;nb&quot;&gt;local          &lt;/span&gt;60s
fedora-nginx            Bound    local-pv-8dla23ds    5Gi       RWO            &lt;span class=&quot;nb&quot;&gt;local          &lt;/span&gt;60s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;understanding-the-vm-image-repository&quot;&gt;Understanding the VM Image Repository&lt;/h2&gt;
&lt;p&gt;At this point we have a namespace, vm-images, that contains PVCs with our VM images on them. Those PVCs represent VM images in the same way AWS’s AMIs represent VM images and this &lt;strong&gt;vm-images namespace is our VM image repository.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Using CDI’s i&lt;a href=&quot;https://github.com/kubevirt/containerized-data-importer/blob/master/doc/clone-datavolume.md#how-to-clone-an-image-from-one-dv-to-another-one&quot;&gt;cross namespace cloning feature&lt;/a&gt;, VM’s can now be launched across multiple namespaces throughout the entire cluster using the PVCs in this “repository”. Note that non-admin users need a special RBAC role to allow for this cross namespace PVC cloning. Any non-admin user who needs the ability to access the vm-images namespace for PVC cloning will need the RBAC permissions outlined &lt;a href=&quot;https://github.com/kubevirt/containerized-data-importer/blob/master/doc/RBAC.md#pvc-cloning&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Below is an example of the RBAC necessary to enable cross namespace cloning from the vm-images namespace to the default namespace using the default service account.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ClusterRole&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cdi-cloner&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cdi.kubevirt.io&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;datavolumes/source&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;create&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;RoleBinding&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default-cdi-cloner&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vm-images&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;subjects&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ServiceAccount&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;roleRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ClusterRole&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cdi-cloner&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;apiGroup&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rbac.authorization.k8s.io&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;horizontally-scaling-vms-using-custom-image&quot;&gt;Horizontally Scaling VMs Using Custom Image&lt;/h1&gt;

&lt;p&gt;Now that we have our immutable custom VM image, we can create as many VMs as we want using that custom image.&lt;/p&gt;

&lt;h2 id=&quot;example-scale-out-vmi-instances-using-the-custom-vm-image&quot;&gt;Example: Scale out VMI instances using the custom VM image.&lt;/h2&gt;

&lt;p&gt;Clone the custom VM image from the vm-images namespace into the namespace the VMI instances will be running in as a &lt;strong&gt;ReadOnlyMany&lt;/strong&gt; PVC. This will allow concurrent access to a single PVC.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cdi.kubevirt.io/v1alpha1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;DataVolume&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-rom&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;pvc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vm-images&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fedora-nginx&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;pvc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;accessModes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ReadOnlyMany&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;5Gi&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, create a VirtualMachineInstanceReplicaSet that references the nginx-rom PVC as an ephemeral volume. With an ephemeral volume, KubeVirt will mount the PVC read only, and use a cow (copy on write) &lt;a href=&quot;https://kubevirt.io/user-guide/#/creation/disks-and-volumes?id=ephemeral&quot;&gt;ephemeral volume&lt;/a&gt; on local storage to back each individual VMI. This ephemeral data’s life cycle is limited to the life cycle of each VMI.&lt;/p&gt;

&lt;p&gt;Here’s an example manifest of a VirtualMachineInstanceReplicaSet starting 5 instances of our nginx server in separate VMIs.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kubevirt.io/v1alpha3&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachineInstanceReplicaSet&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;kubevirt.io/vmReplicaSet&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;replicas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;kubevirt.io/vmReplicaSet&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;devices&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;disks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-image&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;machine&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1Gi&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;terminationGracePeriodSeconds&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;ephemeral&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-image&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;persistentVolumeClaim&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;claimName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-rom&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;cloudInitNoCloud&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;# add any custom logic you want to occur on startup here.&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;echo “cloud-init script execution&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;example-launching-a-single-pet-vm-from-custom-image&quot;&gt;Example: Launching a Single “Pet” VM from Custom Image&lt;/h2&gt;

&lt;p&gt;In the manifest below, we’re starting a new VM with a PVC cloned from our pre-provisioned VM image that contains the nginx server. When the VM boots up, a new PVC will be created in the VM’s namespace that is a clone of the PVC referenced in our vm-images namespace.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kubevirt.io/v1alpha3&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VirtualMachine&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;kubevirt.io/vm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;running&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;kubevirt.io/vm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;devices&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;disks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;datavolumedisk1&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;disk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;bus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;virtio&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;machine&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1Gi&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;terminationGracePeriodSeconds&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;dataVolume&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;datavolumedisk1&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;cloudInitNoCloud&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;# add any custom logic you want to occur on startup here.&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;echo “cloud-init script execution&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cloudinitdisk&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;dataVolumeTemplates&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;pvc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;accessModes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ReadWriteOnce&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;5Gi&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;pvc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vm-images&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fedora-nginx&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;other-custom-creation-image-tools&quot;&gt;Other Custom Creation Image Tools&lt;/h1&gt;

&lt;p&gt;In my example I imported a VM base image into the cluster and used KubeVirt to provision a custom image with a technique that used cloud-init. This may or may not make sense for your use case. It’s possible you need to pre-provision the VM image before importing into the cluster at all.&lt;/p&gt;

&lt;p&gt;If that’s the case, I suggest looking into two tools.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://packer.io/docs/builders/qemu.html&quot;&gt;Packer.io using the qemu builder&lt;/a&gt;. This allows you to automate building custom images on your local machine using configuration files that describe all the build steps. I like this tool because it closely matches the Kubernetes “declarative” approach.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://libguestfs.org/virt-customize.1.html&quot;&gt;Virt-customize&lt;/a&gt; is a cli tool that allows you to customize local VM images by injecting/modifying files on disk and installing packages.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://linux.die.net/man/1/virt-install&quot;&gt;Virt-install&lt;/a&gt; is a cli tool that allows you to automate a VM install as if you were installing it from a cdrom. You’ll want to look into using a kickstart file to fully automate the process.&lt;/p&gt;

&lt;p&gt;The resulting VM image artifact created from any of these tools can then be imported into the cluster in the same way we imported the base image earlier in this document.&lt;/p&gt;</content><author><name>David Vossel</name></author><category term="news" /><category term="kubevirt" /><category term="kubernetes" /><category term="virtual machine" /><category term="VM" /><category term="images" /><category term="storage" /><summary type="html">Building a VM Image Repository</summary></entry></feed>